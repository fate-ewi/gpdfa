
@techreport{stock2005a,
	type = {Working {Paper}},
	title = {Implications of {dynamic} {factor} {models} for {VAR} {analysis}},
	url = {http://www.nber.org/papers/w11467},
	abstract = {This paper considers VAR models incorporating many time series that interact through a few dynamic factors. Several econometric issues are addressed including estimation of the number of dynamic factors and tests for the factor restrictions imposed on the VAR. Structural VAR identification based on timing restrictions, long run restrictions, and restrictions on factor loadings are discussed and practical computational methods suggested. Empirical analysis using U.S. data suggest several (7) dynamic factors, rejection of the exact dynamic factor model but support for an approximate factor model, and sensible results for a SVAR that identifies money policy shocks using timing restrictions.},
	number = {11467},
	urldate = {2018-02-23},
	institution = {National Bureau of Economic Research},
	author = {Stock, James H. and Watson, Mark W.},
	month = jul,
	year = {2005},
	doi = {10.3386/w11467},
	file = {NBER Full Text PDF:/Users/eric.ward/Zotero/storage/YQ9EPF2Q/Stock and Watson - 2005 - Implications of Dynamic Factor Models for VAR Anal.pdf:application/pdf}
}

@article{zuur2003c,
	title = {Estimating common trends in multivariate time series using dynamic factor analysis},
	volume = {14},
	issn = {1099-095X},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/env.611/abstract},
	doi = {10.1002/env.611},
	abstract = {This article discusses dynamic factor analysis, a technique for estimating common trends in multivariate time series. Unlike more common time series techniques such as spectral analysis and ARIMA models, dynamic factor analysis can analyse short, non-stationary time series containing missing values. Typically, the parameters in dynamic factor analysis are estimated by direct optimization, which means that only small data sets can be analysed if computing time is not to become prohibitively long and the chances of obtaining sub-optimal estimates are to be avoided. This article shows how the parameters of dynamic factor analysis can be estimated using the EM algorithm, allowing larger data sets to be analysed. The technique is illustrated on a marine environmental data set. Copyright © 2003 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {7},
	urldate = {2018-02-23},
	journal = {Environmetrics},
	author = {Zuur, A. F. and Fryer, R. J. and Jolliffe, I. T. and Dekker, R. and Beukema, J. J.},
	month = nov,
	year = {2003},
	keywords = {dynamic factor analysis, common trends, EM algorithm, multivariate time series analysis},
	pages = {665--685},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/ESMHRGJM/Zuur et al. - 2003 - Estimating common trends in multivariate time seri.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/5MT5G32P/abstract.html:text/html}
}

@article{zuur2003b,
	title = {Dynamic factor analysis to estimate common trends in fisheries time series},
	volume = {60},
	issn = {0706-652X},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/f03-030},
	doi = {10.1139/f03-030},
	abstract = {Dynamic factor analysis (DFA) is a technique used to detect common patterns in a set of time series and relationships between these series and explanatory variables. Although DFA is used widely in econometric and psychological fields, it has not been used in fisheries and aquatic sciences to the best of our knowledge. To make the technique more widely accessible, an introductory guide for DFA, at an intermediate level, is presented in this paper. A case study is presented. The analysis of 13 landings-per-unit-effort series for Nephrops around northern Europe identified three common trends for 12 of the series, with one series being poorly fitted, but no relationships with the North Atlantic Oscillation (NAO) or sea surface temperature were found. The 12 series could be divided into six groups based on factor loadings from the three trends., L'analyse factorielle dynamique (DFA) est une technique qui permet de détecter les structures communes dans des séries temporelles, ainsi que les relations entre les séries et les variables explicatives. Bien qu'utilisée régulièrement en économétrie et en psychologie, la méthode n'a pas été employée, au meilleur de notre connaissance, dans les domaines des pêches et des sciences aquatiques. On trouvera ici un guide d'introduction à la DFA, à un niveau intermédiaire, qui rendra la méthodologie plus généralement accessible. Nous présentons une étude de cas qui consiste en l'analyse de 13 séries de débarquements de Nephrops par unité d'effort de pêche sur les côtes de l'Europe du Nord. Il y a trois tendances communes à douze des séries; une des séries s'ajuste mal; il n'existe aucune relation ni avec l'oscillation nord-atlantique (NAO), ni avec la température de surface de la mer. Les 12 séries se divisent en six groupes d'après le poids des facteurs dans les trois tendances.[Traduit par la Rédaction]},
	number = {5},
	urldate = {2018-02-23},
	journal = {Canadian Journal of Fisheries and Aquatic Sciences},
	author = {Zuur, A F and Tuck, I D and Bailey, N},
	month = may,
	year = {2003},
	pages = {542--552},
	file = {NRC Research Press PDF fulltext:/Users/eric.ward/Zotero/storage/FTHBJCJL/Zuur et al. - 2003 - Dynamic factor analysis to estimate common trends .pdf:application/pdf;NRC Research Press Snapshot:/Users/eric.ward/Zotero/storage/TXNU8PNG/f03-030.html:text/html}
}

@article{molenaar1985a,
	title = {A dynamic factor model for the analysis of multivariate time series},
	volume = {50},
	issn = {0033-3123, 1860-0980},
	url = {https://link.springer.com/article/10.1007/BF02294246},
	doi = {10.1007/BF02294246},
	abstract = {As a method to ascertain the structure of intra-individual variation,P-technique has met difficulties in the handling of a lagged covariance structure. A new statistical technique, coined dynamic factor analysis, is proposed, which accounts for the entire lagged covariance function of an arbitrary second order stationary time series. Moreover, dynamic factor analysis is shown to be applicable to a relatively short stretch of observations and therefore is considered worthwhile for psychological research. At several places the argumentation is clarified through the use of examples.},
	language = {en},
	number = {2},
	urldate = {2018-02-23},
	journal = {Psychometrika},
	author = {Molenaar, Peter C. M.},
	month = jun,
	year = {1985},
	pages = {181--202},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/VQKPTSLX/BF02294246.html:text/html}
}

@article{lopes2008a,
	title = {Spatial dynamic factor analysis},
	volume = {3},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1340370408},
	doi = {10.1214/08-BA329},
	abstract = {A new class of space-time models derived from standard dynamic factor models is proposed. The temporal dependence is modeled by latent factors while the spatial dependence is modeled by the factor loadings. Factor analytic arguments are used to help identify temporal components that summarize most of the spatial variation of a given region. The temporal evolution of the factors is described in a number of forms to account for different aspects of time variation such as trend and seasonality. The spatial dependence is incorporated into the factor loadings by a combination of deterministic and stochastic elements thus giving them more flexibility and generalizing previous approaches. The new structure implies nonseparable space-time variation to observables, despite its conditionally independent nature, while reducing the overall dimensionality, and hence complexity, of the problem. The number of factors is treated as another unknown parameter and fully Bayesian inference is performed via a reversible jump Markov Chain Monte Carlo algorithm. The new class of models is tested against one synthetic dataset and applied to pollution data obtained from the Clean Air Status and Trends Network (CASTNet). Our factor model exhibited better predictive performance when compared to benchmark models, while capturing important aspects of spatial and temporal behavior of the data.},
	language = {EN},
	number = {4},
	urldate = {2018-02-23},
	journal = {Bayesian Analysis},
	author = {Lopes, Hedibert Freitas and Salazar, Esther and Gamerman, Dani},
	month = dec,
	year = {2008},
	mrnumber = {MR2469799},
	zmnumber = {1330.62356},
	keywords = {forecasting, Gaussian process, spatial interpolation, Bayesian inference, random fields, reversible jump Markov chain Monte Carlo},
	pages = {759--792},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/MH8A5KAW/1340370408.html:text/html}
}

@article{forni2000a,
	title = {The {generalized} {dynamic}-{factor} {model}: {identification} and {estimation}},
	volume = {82},
	issn = {0034-6535},
	shorttitle = {The {Generalized} {Dynamic}-{Factor} {Model}},
	url = {https://doi.org/10.1162/003465300559037},
	doi = {10.1162/003465300559037},
	abstract = {This paper proposes a factor model with infinite dynamics and nonorthogonal idiosyncratic components. The model, which we call the generalized dynamic-factor model, is novel to the literature and generalizes the static approximate factor model of Chamberlain and Rothschild (1983), as well as the exact factor model à la Sargent and Sims (1977). We provide identification conditions, propose an estimator of the common components, prove convergence as both time and cross-sectional size go to infinity at appropriate rates, and present simulation results. We use our model to construct a coincident index for the European Union. Such index is defined as the common component of real GDP within a model including several macroeconomic variables for each European country.},
	number = {4},
	urldate = {2018-02-23},
	journal = {The Review of Economics and Statistics},
	author = {Forni, Mario and Hallin, Marc and Lippi, Marco and Reichlin, Lucrezia},
	month = nov,
	year = {2000},
	pages = {540--554},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/LWFFXP8D/003465300559037.html:text/html}
}

@inproceedings{anderson1956,
	address = {Berkeley, California},
	title = {Statistical inference in factor analysis},
	booktitle = {Proceedings of the {Third} {Berkeley} {Symposium} on {Mathematical} {Statistics} and {Probability}, {Volume} 5: {Contributions} to {Econometrics}, {Industrial} {Research}, and {Psychometry}},
	publisher = {University of California Press},
	author = {Anderson, T. W. and Rubin, H.},
	year = {1956},
	pages = {111--150}
}

@article{lopes2004,
	title = {{Bayesian} {model} {assessment} {in} {factor} {analysis}},
	volume = {14},
	issn = {1017-0405},
	url = {http://www.jstor.org/stable/24307179},
	abstract = {Factor analysis has been one of the most powerful and flexible tools for assessment of multivariate dependence and codependence. Loosely speaking, it could be argued that the origin of its success rests in its very exploratory nature, where various kinds of data-relationships amongst the variables at study can be iteratively verified and/or refuted. Bayesian inference in factor analytic models has received renewed attention in recent years, partly due to computational advances but also partly to applied focuses generating factor structures as exemplified by recent work in financial time series modeling. The focus of our current work is on exploring questions of uncertainty about the number of latent factors in a multivariate factor model, combined with methodological and computational issues of model specification and model fitting. We explore reversible jump MCMC methods that build on sets of parallel Gibbs sampling-based analyses to generate suitable empirical proposal distributions and that address the challenging problem of finding efficient proposals in high-dimensional models. Alternative MCMC methods based on bridge sampling are discussed, and these fully Bayesian MCMC approaches are compared with a collection of popular model selection methods in empirical studies. Various additional computational issues are discussed, including situations where prior information is scarce, and the methods are explored in studies of some simulated data sets and an econometric time series example.},
	number = {1},
	urldate = {2018-02-27},
	journal = {Statistica Sinica},
	author = {Lopes, Hedibert Freitas and West, Mike},
	year = {2004},
	pages = {41--67}
}

@book{harvey1990,
	title = {Forecasting, {structural} {time} {series} {models} and the {Kalman} {filter}},
	isbn = {978-0-521-40573-7},
	abstract = {This book provides a synthesis of concepts and materials that ordinarily appear separately in time series and econometrics literature, presenting a comprehensive review of both theoretical and applied concepts. Perhaps the most novel feature of the book is its use of Kalman filtering together with econometric and time series methodology. From a technical point of view, state space models and the Kalman filter play a key role in the statistical treatment of structural time series models. This technique was originally developed in control engineering but is becoming increasingly important in economics and operations research. The book is primarily concerned with modeling economic and social time series and with addressing the special problems that the treatment of such series pose.},
	language = {en},
	publisher = {Cambridge University Press},
	author = {Harvey, Andrew C.},
	year = {1990},
	note = {Google-Books-ID: Kc6tnRHBwLcC},
	keywords = {Business \& Economics / Econometrics}
}

@article{holmes2012b,
	title = {{MARSS}: {Multivariate} autoregressive state-space models for analyzing time-series data},
	volume = {4},
	abstract = {MARSS is a package for fitting multivariate autoregressive state-space models to time-series data. The MARSS package implements state-space models in a maximum likelihood framework. The core functionality of MARSS is based on likelihood maximization using the Kalman filter/smoother, combined with an EM algorithm. To make comparisons with
other packages available, parameter estimation is also permitted via direct search routines available in ’optim’. The MARSS package allows data to contain missing values and allows a wide variety of model structures and constraints to
be specified (such as fixed or shared parameters). In addition to model-fitting, the package
provides bootstrap routines for simulating data and generating confidence intervals, and multiple options for calculating model selection criteria (such as AIC).},
	number = {1},
	journal = {The R Journal},
	author = {Holmes, E. E. and Ward, E. J. and Wills, K.},
	year = {2012},
	pages = {11--19}
}

@book{durbin2012,
	title = {Time {series} {analysis} by {state} {space} {methods}},
	isbn = {978-0-19-162719-4},
	abstract = {This new edition updates Durbin \& Koopman's important text on the state space approach to time series analysis. The distinguishing feature of state space time series models is that observations are regarded as made up of distinct components such as trend, seasonal, regression elements and disturbance terms, each of which is modelled separately. The techniques that emerge from this approach are very flexible and are capable of handling a much wider range of problems than the main analytical system currently in use for time series analysis, the Box-Jenkins ARIMA system. Additions to this second edition include the filtering of nonlinear and non-Gaussian series. Part I of the book obtains the mean and variance of the state, of a variable intended to measure the effect of an interaction and of regression coefficients, in terms of the observations. Part II extends the treatment to nonlinear and non-normal models. For these, analytical solutions are not available so methods are based on simulation.},
	language = {en},
	publisher = {OUP Oxford},
	author = {Durbin, James and Koopman, Siem Jan},
	month = may,
	year = {2012},
	note = {Google-Books-ID: lGyshsfkLrIC},
	keywords = {Mathematics / Probability \& Statistics / General, Business \& Economics / Statistics, Mathematics / Applied}
}

@techreport{gilbert2005,
	title = {Time {series} {factor} {analysis} with an {application} to {measuring} {money}},
	url = {http://som.eldoc.ub.rug.nl/reports/themeF/2005/05F10/},
	number = {05F10},
	institution = {University of Groningen, SOM Research School},
	author = {Gilbert, Paul D. and Meijer, Erik},
	year = {2005}
}

@article{anderson2017a,
	title = {Black-swan events in animal populations},
	volume = {114},
	copyright = {©  . Freely available online through the PNAS open access option.},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/content/114/12/3252},
	doi = {10.1073/pnas.1611525114},
	abstract = {Black swans are improbable events that nonetheless occur—often with profound consequences. Such events drive important transitions in social systems (e.g., banking collapses) and physical systems (e.g., earthquakes), and yet it remains unclear the extent to which ecological population numbers buffer or suffer from such extremes. Here, we estimate the prevalence and direction of black-swan events (heavy-tailed process noise) in 609 animal populations after accounting for population dynamics (productivity, density dependence, and typical stochasticity). We find strong evidence for black-swan events in ∼∼{\textless}mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"{\textgreater}{\textless}mml:mo{\textgreater}∼{\textless}/mml:mo{\textgreater}{\textless}/mml:math{\textgreater}4\% of populations. These events occur most frequently for birds (7\%), mammals (5\%), and insects (3\%) and are not explained by any life-history covariates but tend to be driven by external perturbations such as climate, severe winters, predators, parasites, or the combined effect of multiple factors. Black-swan events manifest primarily as population die-offs and crashes (86\%) rather than unexpected increases, and ignoring heavy-tailed process noise leads to an underestimate in the magnitude of population crashes. We suggest modelers consider heavy-tailed, downward-skewed probability distributions, such as the skewed Student tt{\textless}mml:math xmlns:mml="http://www.w3.org/1998/Math/MathML"{\textgreater}{\textless}mml:mi{\textgreater}t{\textless}/mml:mi{\textgreater}{\textless}/mml:math{\textgreater} used here, when making forecasts of population abundance. Our results demonstrate the importance of both modeling heavy-tailed downward events in populations, and developing conservation strategies that are robust to ecological surprises.},
	language = {en},
	number = {12},
	urldate = {2018-03-02},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Anderson, Sean C. and Branch, Trevor A. and Cooper, Andrew B. and Dulvy, Nicholas K.},
	month = mar,
	year = {2017},
	pmid = {28270622},
	keywords = {population dynamics, die-offs, ecological risk, ecological surprises, mass mortality},
	pages = {3252--3257},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/XS6B8PIV/Anderson et al. - 2017 - Black-swan events in animal populations.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/4EL6DAQX/3252.html:text/html}
}

@article{ward2007a,
	title = {A state–space mixture approach for estimating catastrophic events in time series data},
	volume = {64},
	issn = {0706-652X},
	url = {http://www.nrcresearchpress.com/doi/abs/10.1139/f07-060},
	doi = {10.1139/f07-060},
	abstract = {Catastrophic events are considered a major contributor to extinction threats, yet are rarely explicitly estimated in population models. We extend the basic state–space population dynamics model to include a mixture distribution for the process error. The mixture distribution consists of a "normal" component, representing regular process error variability, and a "catastrophic" component, representing rare events that negatively affect the population. Direct estimation of parameters is rarely possible using a single time series; however, estimation is possible when time series are combined in hierarchical models. We apply the catastrophic state–space model to simulated time series of abundance from simple, nonlinear population dynamics models. Applications of the model to these simulated time series indicate that population parameters (such as the carrying capacity or growth rate) and observation and process errors are estimated robustly when appropriate time series are available. Our simulations indicate t..., Bien qu'on considère que les événements catastrophiques constituent des menaces d'extinction importantes, ceux-ci sont rarement estimés de façon explicite dans les modèles démographiques. Nous étendons un modèle démographique de base de type état–espace pour inclure une distribution de mélange de l'erreur de processus. La distribution de mélange comprend une composante « normale » qui représente la variabilité de l'erreur de processus ordinaire et une composante « catastrophique » qui représente les événements rares qui affectent la population de façon négative. Il est rarement possible d'estimer directement les variables à partir d'une seule série chronologique, mais cette estimation est possible lorsque plusieurs séries chronologiques sont combinées dans des modèles hiérarchiques. Nous utilisons le modèle état–espace catastrophique avec des séries chronologiques simulées d'abondance provenant de modèles de dynamique de population simples et non linéaires. L'application de ces modèles aux séries chronolo...},
	number = {6},
	urldate = {2018-03-02},
	journal = {Canadian Journal of Fisheries and Aquatic Sciences},
	author = {Ward, Eric J and Hilborn, Ray and Towell, Rod G and Gerber, Leah},
	month = jun,
	year = {2007},
	pages = {899--910},
	file = {NRC Research Press PDF fulltext:/Users/eric.ward/Zotero/storage/77JIQ92L/Ward et al. - 2007 - A state–space mixture approach for estimating cata.pdf:application/pdf;NRC Research Press Snapshot:/Users/eric.ward/Zotero/storage/WPY33UAU/f07-060.html:text/html}
}

@article{praetz1972,
	title = {The {distribution} of {share} {price} {changes}},
	volume = {45},
	issn = {0021-9398},
	url = {http://www.jstor.org/stable/2351598},
	number = {1},
	urldate = {2018-03-02},
	journal = {The Journal of Business},
	author = {Praetz, Peter D.},
	year = {1972},
	pages = {49--55}
}

@article{evin2011,
	title = {Two‐component mixtures of normal, gamma, and {Gumbel} distributions for hydrological applications},
	volume = {47},
	issn = {1944-7973},
	url = {http://onlinelibrary.wiley.com/doi/10.1029/2010WR010266/full},
	doi = {10.1029/2010WR010266},
	abstract = {[1] Whether mixtures of distributions are employed as a flexible modeling device to estimate densities or are used to model data thought to arise from several populations, they provide an efficient tool...},
	language = {en},
	number = {8},
	urldate = {2018-03-02},
	journal = {Water Resources Research},
	author = {Evin, G. and Merleau, J. and Perreault, L.},
	month = aug,
	year = {2011},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/NS9KTQJS/Evin et al. - 2011 - Two‐component mixtures of normal, gamma, and Gumbe.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/I56PIKUD/full.html:text/html}
}

@article{petris2010,
	title = {An {R} {package} for {dynamic} {linear} {models}},
	volume = {36},
	url = {http://www.jstatsoft.org/v36/i12/},
	number = {12},
	journal = {Journal of Statistical Software},
	author = {Petris, Giovanni},
	year = {2010},
	pages = {1--16}
}

@article{standevelopmentteam2016a,
	title = {{RStan}: the {R} interface to {Stan}},
	url = {http://mc-stan.org/},
	author = {{Stan Development Team}},
	year = {2016},
	note = {R package version 2.14.1}
}

@article{carpenter2015,
	title = {Stan: {a} {probabilistic} {programming} {language}},
	journal = {J. Stat. Softw.},
	author = {Carpenter, Bob},
	year = {2015}
}

@article{hoffman2014,
	title = {The {no}-{u}-{turn} {sampler}: {adaptively} {setting} {path} {lengths} in {Hamiltonian} {Monte} {Carlo}},
	volume = {15},
	journal = {Journal of Machine Learning Research},
	author = {Hoffman, Matthew D. and Gelman, Andrew},
	year = {2014},
	keywords = {bibdesk},
	pages = {1593--1623}
}

@article{koop2010,
	title = {Bayesian {multivariate} {time} {series} {methods} for {empirical} {macroeconomics}},
	volume = {3},
	issn = {1551-3076, 1551-3084},
	url = {https://www.nowpublishers.com/article/Details/ECO-013},
	doi = {10.1561/0800000013},
	abstract = {Bayesian Multivariate Time Series Methods for Empirical Macroeconomics},
	language = {English},
	number = {4},
	urldate = {2018-03-08},
	journal = {Foundations and Trends® in Econometrics},
	author = {Koop, Gary and Korobilis, Dimitris},
	month = jul,
	year = {2010},
	pages = {267--358},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/CLW726PC/Koop and Korobilis - 2010 - Bayesian Multivariate Time Series Methods for Empi.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/VBES6HWQ/ECO-013.html:text/html}
}

@article{stock2011,
	title = {Dynamic {factor} {models}},
	url = {http://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780195398649.001.0001/oxfordhb-9780195398649-e-3},
	doi = {10.1093/oxfordhb/9780195398649.013.0003},
	abstract = {This article surveys work on a class of models, dynamic factor models (DFMs), that has received considerable attention in the past decade because of their ability to model simultaneously and consistently data sets in which the number of series exceeds the number of time series observations. The aim of this survey is to describe the key theoretical results, applications, and empirical findings in the recent literature on DFMs. The article is organized as follows. The first issue at hand for the econometrician is to estimate the factors and to ascertain how many factors there are; these two topics are covered in Sections 2 and 3. Once one has reliable estimates of the factors, there are a number of things one can do with them beyond using them for forecasting, including using them as instrumental variables, estimating factor-augmented vector autoregressions, and estimating dynamic stochastic general equilibrium models; these applications are covered in Section 4. Section 5 discusses some extensions.},
	language = {en},
	urldate = {2018-03-08},
	journal = {The Oxford Handbook of Economic Forecasting},
	author = {Stock, James H. and Watson, Mark W.},
	month = jul,
	year = {2011},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/LPILVRAQ/oxfordhb-9780195398649-e-3.html:text/html}
}

@article{bai2015,
	title = {Identification and {Bayesian} {estimation} of {dynamic} {factor} {models}},
	volume = {33},
	issn = {0735-0015},
	url = {https://doi.org/10.1080/07350015.2014.941467},
	doi = {10.1080/07350015.2014.941467},
	abstract = {We consider a set of minimal identification conditions for dynamic factor models. These conditions have economic interpretations and require fewer restrictions than the static factor framework. Under these restrictions, a standard structural vector autoregression (SVAR) with measurement errors can be embedded into a dynamic factor model. More generally, we also consider overidentification restrictions to achieve efficiency. We discuss general linear restrictions, either in the form of known factor loadings or cross-equation restrictions. We further consider serially correlated idiosyncratic errors with heterogeneous dynamics. A numerically stable Bayesian algorithm for the dynamic factor model with general parameter restrictions is constructed for estimation and inference. We show that a square-root form of the Kalman filter improves robustness and accuracy when sampling the latent factors. Confidence intervals (bands) for the parameters of interest such as impulse responses are readily computed. Similar identification conditions are also exploited for multilevel factor models, and they allow us to study the “spill-over” effects of the shocks arising from one group to another. Supplementary materials for technical details are available online.},
	number = {2},
	urldate = {2018-03-08},
	journal = {Journal of Business \& Economic Statistics},
	author = {Bai, Jushan and Wang, Peng},
	month = apr,
	year = {2015},
	keywords = {Cross-equation restrictions, Impulse response function, Multilevel factor model, Spill-over effects},
	pages = {221--240},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/N73MXDKW/07350015.2014.html:text/html}
}

@article{visser2010,
	title = {{depmixS4}: {An} {R} {package} for {Hidden} {Markov} {Models}},
	volume = {36},
	url = {http://www.jstatsoft.org/v36/i07/},
	number = {7},
	journal = {Journal of Statistical Software},
	author = {Visser, Ingmar and Speekenbrink, Maarten},
	year = {2010},
	pages = {1--21}
}

@article{jackson2011,
	title = {Multi-{state} {models} for {panel} {data}: {the} msm {package} for {R}},
	volume = {38},
	url = {http://www.jstatsoft.org/v38/i08/},
	number = {8},
	journal = {Journal of Statistical Software},
	author = {Jackson, Christopher H.},
	year = {2011},
	pages = {1--29}
}

@article{kaiser1958,
	title = {The varimax criterion for analytic rotation in factor analysis},
	volume = {23},
	issn = {0033-3123, 1860-0980},
	url = {https://link.springer.com/article/10.1007/BF02289233},
	doi = {10.1007/BF02289233},
	abstract = {An analytic criterion for rotation is defined. The scientific advantage of analytic criteria over subjective (graphical) rotational procedures is discussed. Carroll's criterion and the quartimax criterion are briefly reviewed; the varimax criterion is outlined in detail and contrasted both logically and numerically with the quartimax criterion. It is shown that thenormal varimax solution probably coincides closely to the application of the principle of simple structure. However, it is proposed that the ultimate criterion of a rotational procedure is factorial invariance, not simple structure—although the two notions appear to be highly related. The normal varimax criterion is shown to be a two-dimensional generalization of the classic Spearman case, i.e., it shows perfect factorial invariance for two pure clusters. An example is given of the invariance of a normal varimax solution for more than two factors. The oblique normal varimax criterion is stated. A computational outline for the orthogonal normal varimax is appended.},
	language = {en},
	number = {3},
	urldate = {2018-03-09},
	journal = {Psychometrika},
	author = {Kaiser, Henry F.},
	month = sep,
	year = {1958},
	pages = {187--200},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/CBTNV4CJ/BF02289233.html:text/html}
}

@article{thorson2015e,
	title = {Spatial factor analysis: a new tool for estimating joint species distributions and correlations in species range},
	volume = {6},
	issn = {2041-210X},
	shorttitle = {Spatial factor analysis},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/2041-210X.12359/abstract},
	doi = {10.1111/2041-210X.12359},
	abstract = {* Predicting and explaining the distribution and density of species is one of the oldest concerns in ecology. Species distributions can be estimated using geostatistical methods, which estimate a latent spatial variable explaining observed variation in densities, but geostatistical methods may be imprecise for species with low densities or few observations. Additionally, simple geostatistical methods fail to account for correlations in distribution among species and generally estimate such cross-correlations as a post hoc exercise.


* We therefore present spatial factor analysis (SFA), a spatial model for estimating a low-rank approximation to multivariate data, and use it to jointly estimate the distribution of multiple species simultaneously. We also derive an analytic estimate of cross-correlations among species from SFA parameters.


* As a first example, we show that distributions for 10 bird species in the breeding bird survey in 2012 can be parsimoniously represented using only five spatial factors. As a second case study, we show that forward prediction of catches for 20 rockfishes (Sebastes spp.) off the U.S. West Coast is more accurate using SFA than analysing each species individually. Finally, we show that single-species models give a different picture of cross-correlations than joint estimation using SFA.


* Spatial factor analysis complements a growing list of tools for jointly modelling the distribution of multiple species and provides a parsimonious summary of cross-correlation without requiring explicit declaration of habitat variables. We conclude by proposing future research that would model species cross-correlations using dissimilarity of species’ traits, and the development of spatial dynamic factor analysis for a low-rank approximation to spatial time-series data.},
	language = {en},
	number = {6},
	urldate = {2018-03-09},
	journal = {Methods in Ecology and Evolution},
	author = {Thorson, James T. and Scheuerell, Mark D. and Shelton, Andrew O. and See, Kevin E. and Skaug, Hans J. and Kristensen, Kasper},
	month = jun,
	year = {2015},
	keywords = {Gaussian process, geostatistics, Gaussian random field, factor analysis, habitat envelope model, hierarchical model, joint species distribution models, mixed-effects model, spatial factor analysis},
	pages = {627--637},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/ZHKATEKD/Thorson et al. - 2015 - Spatial factor analysis a new tool for estimating.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/52HGA7GF/abstract.html:text/html}
}

@article{lopes2011,
	title = {Generalized spatial dynamic factor models},
	volume = {55},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947310003634},
	doi = {10.1016/j.csda.2010.09.020},
	abstract = {This paper introduces a new class of spatio-temporal models for measurements belonging to the exponential family of distributions. In this new class, the spatial and temporal components are conditionally independently modeled via a latent factor analysis structure for the (canonical) transformation of the measurements mean function. The factor loadings matrix is responsible for modeling spatial variation, while the common factors are responsible for modeling the temporal variation. One of the main advantages of our model with spatially structured loadings is the possibility of detecting similar regions associated to distinct dynamic factors. We also show that the new class outperforms a large class of spatial-temporal models that are commonly used in the literature. Posterior inference for fixed parameters and dynamic latent factors is performed via a custom tailored Markov chain Monte Carlo scheme for multivariate dynamic systems that combines extended Kalman filter-based Metropolis–Hastings proposal densities with block-sampling schemes. Factor model uncertainty is also fully addressed by a reversible jump Markov chain Monte Carlo algorithm designed to learn about the number of common factors. Three applications, two based on synthetic Gamma and Bernoulli data and one based on real Bernoulli data, are presented in order to illustrate the flexibility and generality of the new class of models, as well as to discuss features of the proposed MCMC algorithm.},
	number = {3},
	urldate = {2018-03-09},
	journal = {Computational Statistics \& Data Analysis},
	author = {Lopes, Hedibert Freitas and Gamerman, Dani and Salazar, Esther},
	month = mar,
	year = {2011},
	keywords = {Gaussian process, Exponential family, Factor model, Markov chain Monte Carlo, Reversible jump, Sampling schemes},
	pages = {1319--1330},
	file = {ScienceDirect Snapshot:/Users/eric.ward/Zotero/storage/HKHLY5FQ/S0167947310003634.html:text/html}
}

@article{chow2011,
	title = {Bayesian estimation of semiparametric nonlinear dynamic factor analysis models using the {Dirichlet} process prior},
	volume = {64},
	issn = {0007-1102},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3199348/},
	doi = {10.1348/000711010X497262},
	abstract = {Parameters in time series and other dynamic models often show complex range restrictions and their distributions may deviate substantially from multivariate normal or other standard parametric distributions. We use the truncated Dirichlet process (DP) as a non-parametric prior for such dynamic parameters in a novel nonlinear Bayesian dynamic factor analysis model. This is equivalent to specifying the prior distribution to be a mixture distribution composed of an unknown number of discrete point masses (or clusters). The stick-breaking prior and the blocked Gibbs sampler are used to enable efficient simulation of posterior samples. Using a series of empirical and simulation examples, we illustrate the flexibility of the proposed approach in approximating distributions of very diverse shapes.},
	number = {Pt 1},
	urldate = {2018-03-14},
	journal = {The British journal of mathematical and statistical psychology},
	author = {Chow, Sy-Miin and Tang, Niansheng and Yuan, Ying and Song, Xinyuan and Zhu, Hongtu},
	month = feb,
	year = {2011},
	pmid = {21506946},
	pmcid = {PMC3199348},
	pages = {69--106},
	file = {PubMed Central Full Text PDF:/Users/eric.ward/Zotero/storage/LA9BBZ4Q/Chow et al. - 2011 - Bayesian estimation of semiparametric nonlinear dy.pdf:application/pdf}
}

@book{zucchini2017,
	title = {Hidden {Markov} {Models} for {time} {series}: {an} {introduction} {using} {R}, {Second} {Edition}},
	isbn = {978-1-4822-5384-9},
	shorttitle = {Hidden {Markov} {Models} for {Time} {Series}},
	abstract = {Hidden Markov Models for Time Series: An Introduction Using R, Second Edition illustrates the great flexibility of hidden Markov models (HMMs) as general-purpose models for time series data. The book provides a broad understanding of the models and their uses. After presenting the basic model formulation, the book covers estimation, forecasting, decoding, prediction, model selection, and Bayesian inference for HMMs. Through examples and applications, the authors describe how to extend and generalize the basic model so that it can be applied in a rich variety of situations. The book demonstrates how HMMs can be applied to a wide range of types of time series: continuous-valued, circular, multivariate, binary, bounded and unbounded counts, and categorical observations. It also discusses how to employ the freely available computing environment R to carry out the computations. Features  Presents an accessible overview of HMMs Explores a variety of applications in ecology, finance, epidemiology, climatology, and sociology Includes numerous theoretical and programming exercises Provides most of the analysed data sets online New to the second edition  A total of five chapters on extensions, including HMMs for longitudinal data, hidden semi-Markov models and models with continuous-valued state process New case studies on animal movement, rainfall occurrence and capture–recapture data},
	language = {en},
	publisher = {CRC Press},
	author = {Zucchini, Walter and MacDonald, Iain L. and Langrock, Roland},
	month = dec,
	year = {2017},
	note = {Google-Books-ID: KlWzDAAAQBAJ},
	keywords = {Mathematics / Probability \& Statistics / General}
}

@article{ward2019,
	title = {Modeling regimes with extremes: the bayesdfa package for identifying and forecasting common trends and anomalies in multivariate time-series data},
	volume = {11},
	issn = {2073-4859},
	shorttitle = {Modeling regimes with extremes},
	url = {https://journal.r-project.org/archive/2019/RJ-2019-007/index.html},
	doi = {10.32614/RJ-2019-007},
	abstract = {The bayesdfa package provides a ﬂexible Bayesian modeling framework for applying dynamic factor analysis (DFA) to multivariate time-series data as a dimension reduction tool. The core estimation is done with the Stan probabilistic programming language. In addition to being one of the few Bayesian implementations of DFA, novel features of this model include (1) optionally modeling latent process deviations as drawn from a Student-t distribution to better model extremes, and (2) optionally including autoregressive and moving-average components in the latent trends. Besides estimation, we provide a series of plotting functions to visualize trends, loadings, and model predicted values. A secondary analysis for some applications is to identify regimes in latent trends. We provide a ﬂexible Bayesian implementation of a Hidden Markov Model — also written with Stan — to characterize regime shifts in latent processes. We provide simulation testing and details on parameter sensitivities in supplementary information.},
	language = {en},
	number = {2},
	urldate = {2020-12-04},
	journal = {The R Journal},
	author = {Ward, J., Eric and Anderson, C., Sean and Damiano, A., Luis and Hunsicker, E., Mary and Litzow, A., Michael},
	year = {2019},
	pages = {46},
	file = {Ward et al. - 2019 - Modeling regimes with extremes the bayesdfa packa.pdf:/Users/eric.ward/Zotero/storage/IQ3GMFKG/Ward et al. - 2019 - Modeling regimes with extremes the bayesdfa packa.pdf:application/pdf}
}

@article{bograd2003,
	series = {{CalCOFI}: {A} {Half} {Century} of {Physical}, {Chemical} and {Biological} {Research} in the {California} {Current} {System}},
	title = {{CalCOFI}: a half century of physical, chemical, and biological research in the {California} {Current} {system}},
	volume = {50},
	issn = {0967-0645},
	shorttitle = {{CalCOFI}},
	url = {http://www.sciencedirect.com/science/article/pii/S096706450300122X},
	doi = {10.1016/S0967-0645(03)00122-X},
	abstract = {The California Cooperative Oceanic Fisheries Investigations (CalCOFI) program has been sampling the physics, chemistry, and biology of the California Current System since 1949, making it the world's longest-running multi-disciplinary oceanographic field program. Founded by leading marine scientists, CalCOFI from its inception took an ecosystem approach to understanding physical–biological coupling in the ocean. Its 54-year time series (and counting) now permits an exploration of a range of oceanographic and fisheries problems across a broad temporal spectrum. As a celebration of more than half a century of CalCOFI, this issue presents 13 manuscripts that sample the breadth of integrated marine research conducted under its auspices.},
	language = {en},
	number = {14},
	urldate = {2020-12-04},
	journal = {Deep Sea Research Part II: Topical Studies in Oceanography},
	author = {Bograd, Steven J and Checkley, David A and Wooster, Warren S},
	month = aug,
	year = {2003},
	pages = {2349--2353},
	file = {ScienceDirect Snapshot:/Users/eric.ward/Zotero/storage/NH9NWY8U/S096706450300122X.html:text/html}
}

@article{mosek2000,
	title = {Abundance and distribution of rockfish ({Sebastes}) larvae in the {Southern} {California} {Bight} in relation to environmental conditions and fishery exploitation},
	volume = {41},
	abstract = {In this study we describe seasonal, interannual, and long-term changes in the larval abundance of six rock-fish (Sehastes) taxa in relation to spawning biomass and to variability in the ocean environment. We used rock-fish larvae from a total of 11,472 CalCOFI plankton tows taken in the Southern California Bight from 1951 to 1998. Species included in the study were bocaccio (S. paucispinis), cowcod (S . levis), shortbelly rockfish (S. jordani), aurora rockfish (S. uuvoya), and splitnose rock-fish (S. diplopyou). Interannual trends in occurrence and abundance are described for each species in relation to biomass trends of adults and to changes in the ocean en-vironment caused by ENSO events and by the cool and warm regimes of the Pacific Decadal Oscillation (PDO). Larval abundance of S. puucispinis and S. levis declined abruptly during the shift to a warm regime and contin-ued to decline, as did the adult biomass. Abundance of S. jovdani larvae declined during the regime shift but in-creased after the 1982-83 El Niiio, reaching the peak value for the time series in 1991. Within each regime, minor declines in larval occurrence and abundance were associated with ENSO episodes. The tightly grouped series of three La Niiia events in 1970-76 immediately preceded the shift from the cool to the warm regime late in 1976 and may have contributed to the marked decline in larval occurrence and abundance that, for most species, continued through the 1982-83 El Niiio. The decline in larval rockfish abundance during the regime shift may be a consequence of the decline in rockfish populations caused by the expanding rockfish fishery; however, the ocean environment may be a causal fac-tor, because larvae of S. jovdani, an unexploited species, underwent declines similar to those of fishery target species during that period.},
	journal = {Abundance and distribution of rockfish larvae CalCOFl Rep.},
	author = {Mosek, H and Charter, L and Watson, William and Ambrose, Iiaviii and Shakon, N and Charter, K and Saniiknoi, Elaine and Fisheiies, Southwest and Center, Science and Fi, Manne and Service, Hene},
	month = jan,
	year = {2000},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/WQN224VM/Mosek et al. - 2000 - Abundance and distribution of rockfish (Sebastes) .pdf:application/pdf}
}

@article{golding2016,
	title = {Fast and flexible {Bayesian} species distribution modelling using {Gaussian} processes},
	volume = {7},
	copyright = {© 2016 The Authors. Methods in Ecology and Evolution published by John Wiley \& Sons Ltd on behalf of British Ecological Society.},
	issn = {2041-210X},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.12523},
	doi = {https://doi.org/10.1111/2041-210X.12523},
	abstract = {Species distribution modelling (SDM) is widely used in ecology, and predictions of species distributions inform both policy and ecological debates. Therefore, methods with high predictive accuracy and those that enable biological interpretation are preferable. Gaussian processes (GPs) are a highly flexible approach to statistical modelling and have recently been proposed for SDM. GP models fit smooth, but potentially complex response functions that can account for high-dimensional interactions between predictors. We propose fitting GP SDMs using deterministic numerical approximations, rather than Markov chain Monte Carlo methods in order to make GPs more computationally efficient and easy to use. We introduce GP models and their application to SDM, illustrate how ecological knowledge can be incorporated into GP SDMs via Bayesian priors and formulate a simple GP SDM that can be fitted efficiently. This model can be fitted either by learning the hyperparameters or by using a fixed approximation to them. Using a subset of the North American Breeding Bird Survey data set, we compare the out-of-sample predictive accuracy of these models with several commonly used SDM approaches for both presence/absence and presence-only data. Predictive accuracy of GP SDMs fitted by Laplace approximation was greater than boosted regression trees, generalized additive models (GAMs) and logistic regression when trained on presence/absence data and greater than all of these models plus MaxEnt when trained on presence-only data. GP SDMs fitted using a fixed approximation to hyperparameters were no less accurate than those with MAP estimation and on average 70 times faster, equivalent in speed to GAMs. As well as having strong predictive power for this data set, GP SDMs offer a convenient method for incorporating prior knowledge of the species' ecology. By fitting these methods using efficient numerical approximations, they may easily be applied to large data sets and automatically for many species. An r package, GRaF, is provided to enable SDM users to fit GP models.},
	language = {en},
	number = {5},
	urldate = {2020-12-10},
	journal = {Methods in Ecology and Evolution},
	author = {Golding, Nick and Purse, Bethan V.},
	year = {2016},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12523},
	keywords = {boosted regression trees, Gaussian processes, generalized additive models, MaxEnt, species distribution models},
	pages = {598--608},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/TENDBUYU/Golding and Purse - 2016 - Fast and flexible Bayesian species distribution mo.pdf:application/pdf}
}

@article{munch2005,
	title = {Bayesian nonparametric analysis of stockrecruitment relationships},
	volume = {62},
	doi = {10.1139/f05-073},
	abstract = {Abstract The relationship between current abundance,and future recruitment to the stock is fundamental to managing,fish populations. There is general agreement about the basic attributes such a relationship should possess. However, many different models may be derived from these attributes and the data are often insufficient to distinguish among,them. Although nonparametric methods,may be used to circumvent this problem, these are devoid of biological underpinnings. Here we present a Bayesian nonparametric approach that allows straightforward incorporation of prior biological information and show how it may be used to estimate several fishery reference points. We applied this method to several artificial data sets generated from a variety of parametric models and compare the results to the fit of Ricker and Beverton- Holt models. We found that the Bayesian nonparametric method,fit the data nearly as good as the true parametric model and always performed better than incorrect parametric alternatives. The estimated reference points agree closely with true values calculated for the underlying parametric model. Finally, we apply the method,to empirical data for lingcod and several salmonids. Since this method is capable of reproducing the behavior of any of the parametric models and provides flexible, data-driven estimates of stock-recruitment relationships,it should be of greatvalue in fisheries applications where the true functional relationship is always unknown.},
	journal = {Canadian Journal of Fisheries and Aquatic Sciences - CAN J FISHERIES AQUAT SCI},
	author = {Munch, Stephan and Kottas, Athanasios and Mangel, Marc},
	month = aug,
	year = {2005},
	pages = {1808--1821},
	file = {Submitted Version:/Users/eric.ward/Zotero/storage/VZIE6KN2/Munch et al. - 2005 - Bayesian nonparametric analysis of stockrecruitme.pdf:application/pdf}
}

@article{riutort-mayol2020,
	title = {Practical {Hilbert} space approximate {Bayesian} {Gaussian} processes for probabilistic programming},
	url = {http://arxiv.org/abs/2004.11408},
	abstract = {Gaussian processes are powerful non-parametric probabilistic models for stochastic functions. However they entail a complexity that is computationally intractable when the number of observations is large, especially when estimated with fully Bayesian methods such as Markov chain Monte Carlo. In this paper, we focus on a novel approach for low-rank approximate Bayesian Gaussian processes, based on a basis function approximation via Laplace eigenfunctions for stationary covariance functions. The main contribution of this paper is a detailed analysis of the performance and practical implementation of the method in relation to key factors such as the number of basis functions, domain of the prediction space, and smoothness of the latent function. We provide intuitive visualizations and recommendations for choosing the values of these factors, which make it easier for users to improve approximation accuracy and computational performance. We also propose diagnostics for checking that the number of basis functions and the domain of the prediction space are adequate given the data. The proposed approach is simple and exhibits an attractive computational complexity due to its linear structure, and it is easy to implement in probabilistic programming frameworks. Several illustrative examples of the performance and applicability of the method in the probabilistic programming language Stan are presented together with the underlying Stan model code.},
	urldate = {2020-12-10},
	journal = {arXiv:2004.11408 [stat]},
	author = {Riutort-Mayol, Gabriel and Bürkner, Paul-Christian and Andersen, Michael R. and Solin, Arno and Vehtari, Aki},
	month = apr,
	year = {2020},
	note = {arXiv: 2004.11408},
	keywords = {Statistics - Computation, Statistics - Methodology},
	file = {arXiv Fulltext PDF:/Users/eric.ward/Zotero/storage/WKNKX9QI/Riutort-Mayol et al. - 2020 - Practical Hilbert space approximate Bayesian Gauss.pdf:application/pdf;arXiv.org Snapshot:/Users/eric.ward/Zotero/storage/HGTN96VZ/2004.html:text/html}
}

@article{kimeldorf1970,
	title = {A {correspondence} {between} {Bayesian} {estimation} on {stochastic} {processes} and {smoothing} by {splines}},
	volume = {41},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2239347},
	number = {2},
	urldate = {2020-12-10},
	journal = {The Annals of Mathematical Statistics},
	author = {Kimeldorf, George S. and Wahba, Grace},
	year = {1970},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {495--502}
}

@article{klein2017,
	title = {Effects of climate change on four {New} {England} groundfish species},
	volume = {27},
	issn = {1573-5184},
	url = {https://doi.org/10.1007/s11160-016-9444-z},
	doi = {10.1007/s11160-016-9444-z},
	abstract = {Multiple groundfish stocks in New England remain depleted despite management measures that have been effective elsewhere. A growing body of research suggests that environmental change driven by increasing concentrations of carbon dioxide in the atmosphere and ocean is unfolding more rapidly in New England than elsewhere, and is an important factor in the failure of these stocks to respond to management. We reviewed research on effects of changes in temperature, salinity, dissolved oxygen, pH, and ocean currents on pelagic life stages, post-settlement life stages, and reproduction of four species in the New England groundfish fishery: Atlantic cod (Gadus morhua), haddock (Melanogrammus aeglefinus), winter flounder (Pseudopleuronectes americanus), and yellowtail flounder (Limanda ferruginea). The volume of research on cod was nearly equal to that on the other three species combined. Similarly, many more studies examined effects of temperature than other factors. The majority of studies suggest adverse outcomes, with less evidence for mixed or positive effects. However, for all of the factors other than temperature, there are more knowledge gaps than known effects. Importantly, most work to date examines impacts in isolation, but effects might combine in nonlinear ways and cause stronger reductions in stock productivity than expected. Management strategies will need to account for known effects, nonlinear interactions, and uncertainties if fisheries in New England are to adapt to environmental change.},
	language = {en},
	number = {2},
	urldate = {2020-12-11},
	journal = {Reviews in Fish Biology and Fisheries},
	author = {Klein, Emily S. and Smith, Sarah L. and Kritzer, Jacob P.},
	month = jun,
	year = {2017},
	pages = {317--338}
}

@article{MADEIRA2017146,
	title = {Thermal stress, thermal safety margins and acclimation capacity in tropical shallow waters—{an} experimental approach testing multiple end-points in two common fish},
	volume = {81},
	issn = {1470-160X},
	url = {http://www.sciencedirect.com/science/article/pii/S1470160X17303059},
	doi = {https://doi.org/10.1016/j.ecolind.2017.05.050},
	abstract = {Tropical organisms are predicted to be among the most impacted by increasing sea surface temperatures, particularly those from intertidal habitats. In this study, a complete thermal biology assessment was conducted for two widespread tropical Atlantic shallow reef fish: Abudefduf saxatilis (damselfish) and Scartella cristata (blenny), which make extensive use of tide pools. The main objectives were to measure the time-course changes during one month in i) thermal and oxidative stress biomarkers (in gills, muscle and skin), ii) upper thermal limits, acclimation capacity and thermal safety margins and iii) body size, condition and energy reserves (total protein and lipid contents), under two temperature treatments (control – mean summer temperature, and elevated temperature −+3°C, as projected by climate warming scenarios for the end of this century). Results from biomarker analyses suggest that under increased temperature, both species displayed a typical response of physiological stress characterized by the activation of molecular chaperones and antioxidant protection. Both species presented a significant acclimation potential in the long term, as shown by increased critical thermal maxima values at higher temperature. However, these species may already be at risk during summer heat waves, as thermal safety margins for both species were low. Additionally, despite acclimation, some energetic tradeoffs may exist, since specimens from both species showed smaller body sizes at higher temperature (even though maintaining body condition). Finally, temperature treatments had a significant influence not only in the total amount of energy reserves (lipid contents) but also in their rate of deposition or depletion (total proteins and lipid contents). This is the first multi-end-point holistic approach to assess the impact of warming in shallow tropical water fish and it highlights the high risk that intertidal organisms are facing in both present and future sea surface temperature conditions.},
	journal = {Ecological Indicators},
	author = {Madeira, Carolina and Mendonça, Vanessa and Leal, Miguel C. and Flores, Augusto A.V. and Cabral, Henrique N. and Diniz, Mário S. and Vinagre, Catarina},
	year = {2017},
	keywords = {Biomarkers, Environmental biomonitoring, Intertidal, Ocean warming, Thermal tolerance, Tropical fish},
	pages = {146 -- 158}
}

@article{dennis2006,
	title = {Estimating {density} {dependence}, {process} {noise}, and {observation} {error}},
	volume = {76},
	copyright = {© 2006 by the Ecological Society of America},
	issn = {1557-7015},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/0012-9615%282006%2976%5B323%3AEDDPNA%5D2.0.CO%3B2},
	doi = {https://doi.org/10.1890/0012-9615(2006)76[323:EDDPNA]2.0.CO;2},
	abstract = {We describe a discrete-time, stochastic population model with density dependence, environmental-type process noise, and lognormal observation or sampling error. The model, a stochastic version of the Gompertz model, can be transformed into a linear Gaussian state-space model (Kalman filter) for convenient fitting to time series data. The model has a multivariate normal likelihood function and is simple enough for a variety of uses ranging from theoretical study of parameter estimation issues to routine data analyses in population monitoring. A special case of the model is the discrete-time, stochastic exponential growth model (density independence) with environmental-type process error and lognormal observation error. We describe two methods for estimating parameters in the Gompertz state-space model, and we compare the statistical qualities of the methods with computer simulations. The methods are maximum likelihood based on observations and restricted maximum likelihood based on first differences. Both offer adequate statistical properties. Because the likelihood function is identical to a repeated-measures analysis of variance model with a random time effect, parameter estimates can be calculated using PROC MIXED of SAS. We use the model to analyze a data set from the Breeding Bird Survey. The fitted model suggests that over 70\% of the noise in the population's growth rate is due to observation error. The model describes the autocovariance properties of the data especially well. While observation error and process noise variance parameters can both be estimated from one time series, multimodal likelihood functions can and do occur. For data arising from the model, the statistically consistent parameter estimates do not necessarily correspond to the global maximum in the likelihood function. Maximization, simulation, and bootstrapping programs must accommodate the phenomenon of multimodal likelihood functions to produce statistically valid results.},
	language = {en},
	number = {3},
	urldate = {2020-12-18},
	journal = {Ecological Monographs},
	author = {Dennis, Brian and Ponciano, José Miguel and Lele, Subhash R. and Taper, Mark L. and Staples, David F.},
	year = {2006},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1890/0012-9615\%282006\%2976\%5B323\%3AEDDPNA\%5D2.0.CO\%3B2},
	keywords = {Kalman filter, Breeding Bird Survey, environmental noise, Gompertz growth model, measurement error, multimodal likelihood, observation error, process noise, sampling error, state-space model, stationary distribution, stochastic population model},
	pages = {323--341},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/K43UCZMQ/0012-9615(2006)76[323EDDPNA]2.0.html:text/html;Submitted Version:/Users/eric.ward/Zotero/storage/TMS9VHBY/Dennis et al. - 2006 - Estimating Density Dependence, Process Noise, and .pdf:application/pdf}
}

@article{wood2011,
	title = {Fast stable restricted maximum likelihood and marginal likelihood estimation of semiparametric generalized linear models},
	volume = {73},
	copyright = {© 2010 Royal Statistical Society},
	issn = {1467-9868},
	url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-9868.2010.00749.x},
	doi = {https://doi.org/10.1111/j.1467-9868.2010.00749.x},
	abstract = {Summary. Recent work by Reiss and Ogden provides a theoretical basis for sometimes preferring restricted maximum likelihood (REML) to generalized cross-validation (GCV) for smoothing parameter selection in semiparametric regression. However, existing REML or marginal likelihood (ML) based methods for semiparametric generalized linear models (GLMs) use iterative REML or ML estimation of the smoothing parameters of working linear approximations to the GLM. Such indirect schemes need not converge and fail to do so in a non-negligible proportion of practical analyses. By contrast, very reliable prediction error criteria smoothing parameter selection methods are available, based on direct optimization of GCV, or related criteria, for the GLM itself. Since such methods directly optimize properly defined functions of the smoothing parameters, they have much more reliable convergence properties. The paper develops the first such method for REML or ML estimation of smoothing parameters. A Laplace approximation is used to obtain an approximate REML or ML for any GLM, which is suitable for efficient direct optimization. This REML or ML criterion requires that Newton–Raphson iteration, rather than Fisher scoring, be used for GLM fitting, and a computationally stable approach to this is proposed. The REML or ML criterion itself is optimized by a Newton method, with the derivatives required obtained by a mixture of implicit differentiation and direct methods. The method will cope with numerical rank deficiency in the fitted model and in fact provides a slight improvement in numerical robustness on the earlier method of Wood for prediction error criteria based smoothness selection. Simulation results suggest that the new REML and ML methods offer some improvement in mean-square error performance relative to GCV or Akaike's information criterion in most cases, without the small number of severe undersmoothing failures to which Akaike's information criterion and GCV are prone. This is achieved at the same computational cost as GCV or Akaike's information criterion. The new approach also eliminates the convergence failures of previous REML- or ML-based approaches for penalized GLMs and usually has lower computational cost than these alternatives. Example applications are presented in adaptive smoothing, scalar on function regression and generalized additive model selection.},
	language = {en},
	number = {1},
	urldate = {2020-12-18},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Wood, Simon N.},
	year = {2011},
	note = {\_eprint: https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-9868.2010.00749.x},
	keywords = {Model selection, Adaptive smoothing, Generalized additive mixed model, Generalized additive model, Generalized cross-validation, Marginal likelihood, Penalized generalized linear model, Penalized regression splines, Restricted maximum likelihood, Scalar on function regression, Stable computation},
	pages = {3--36},
	file = {Accepted Version:/Users/eric.ward/Zotero/storage/YN3C2FMS/Wood - 2011 - Fast stable restricted maximum likelihood and marg.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/ETCPLMZX/j.1467-9868.2010.00749.html:text/html}
}

@article{anderson2019b,
	title = {Black swans in space: modeling spatiotemporal processes with extremes},
	volume = {100},
	copyright = {© 2018 by the Ecological Society of America},
	issn = {1939-9170},
	shorttitle = {Black swans in space},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1002/ecy.2403},
	doi = {https://doi.org/10.1002/ecy.2403},
	abstract = {In ecological systems, extremes can happen in time, such as population crashes, or in space, such as rapid range contractions. However, current methods for joint inference about temporal and spatial dynamics (e.g., spatiotemporal modeling with Gaussian random fields) may perform poorly when underlying processes include extreme events. Here we introduce a model that allows for extremes to occur simultaneously in time and space. Our model is a Bayesian predictive-process GLMM (generalized linear mixed-effects model) that uses a multivariate-t distribution to describe spatial random effects. The approach is easily implemented with our flexible R package glmmfields. First, using simulated data, we demonstrate the ability to recapture spatiotemporal extremes, and explore the consequences of fitting models that ignore such extremes. Second, we predict tree mortality from mountain pine beetle (Dendroctonus ponderosae) outbreaks in the U.S. Pacific Northwest over the last 16 yr. We show that our approach provides more accurate and precise predictions compared to traditional spatiotemporal models when extremes are present. Our R package makes these models accessible to a wide range of ecologists and scientists in other disciplines interested in fitting spatiotemporal GLMMs, with and without extremes.},
	language = {en},
	number = {1},
	urldate = {2020-12-18},
	journal = {Ecology},
	author = {Anderson, Sean C. and Ward, Eric J.},
	year = {2019},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1002/ecy.2403},
	keywords = {spatiotemporal models, random fields, Stan, Bayesian statistics, ecological extremes, geostatistical models, heavy-tailed distributions, mountain pine beetle, multivariate-t distribution, spatial statistics},
	pages = {e02403},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/4FLP3XKY/ecy.html:text/html}
}

@article{patterson2008,
	title = {State–space models of individual animal movement},
	volume = {23},
	issn = {0169-5347},
	url = {http://www.sciencedirect.com/science/article/pii/S0169534707003588},
	doi = {10.1016/j.tree.2007.10.009},
	abstract = {Detailed observation of the movement of individual animals offers the potential to understand spatial population processes as the ultimate consequence of individual behaviour, physiological constraints and fine-scale environmental influences. However, movement data from individuals are intrinsically stochastic and often subject to severe observation error. Linking such complex data to dynamical models of movement is a major challenge for animal ecology. Here, we review a statistical approach, state–space modelling, which involves changing how we analyse movement data and draw inferences about the behaviours that shape it. The statistical robustness and predictive ability of state–space models make them the most promising avenue towards a new type of movement ecology that fuses insights from the study of animal behaviour, biogeography and spatial population dynamics.},
	language = {en},
	number = {2},
	urldate = {2020-12-18},
	journal = {Trends in Ecology \& Evolution},
	author = {Patterson, Toby A. and Thomas, Len and Wilcox, Chris and Ovaskainen, Otso and Matthiopoulos, Jason},
	month = feb,
	year = {2008},
	pages = {87--94},
	file = {ScienceDirect Snapshot:/Users/eric.ward/Zotero/storage/5WWL25IB/S0169534707003588.html:text/html}
}

@article{munch2018,
	title = {Nonlinear dynamics and noise in fisheries recruitment: {a} global meta-analysis},
	volume = {19},
	copyright = {© 2018 John Wiley \& Sons Ltd},
	issn = {1467-2979},
	shorttitle = {Nonlinear dynamics and noise in fisheries recruitment},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/faf.12304},
	doi = {https://doi.org/10.1111/faf.12304},
	abstract = {The relative importance of environmental and intrinsic controls on recruitment in fishes has been studied for over a century. Despite this, we are not much closer to predicting recruitment. Rather, recent analyses suggest that recruitment is virtually independent of stock size and, instead, seems to occur in distinct environmental regimes. This issue of whether or not recruitment and subsequent production are coupled to stock size is highly relevant to management. Here, we apply empirical dynamical modelling (EDM) to a global database of 185 fish populations to address the questions of whether or not variation in recruitment is (a) predictable and (b) coupled to stock size. We find that a substantial fraction of recruitment variation is predictable using only the observed history of fluctuations ( 40\% on average). In addition, although recruitment is often coupled to stock size (107 of 185 stocks), stock size alone explains very little of the variation in recruitment; In 90\% of the stocks analysed, EDM forecasts have substantially lower prediction error than models based solely on stock size. We find that predictability varies across taxa and improves with the number of generations that have been sampled. In the light of these results, we suggest that EDM will be of greatest use in managing relatively short-lived species.},
	language = {en},
	number = {6},
	urldate = {2020-12-18},
	journal = {Fish and Fisheries},
	author = {Munch, Stephan B. and Giron‐Nava, Alfredo and Sugihara, George},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/faf.12304},
	keywords = {recruitment, empirical dynamical modelling, gaussian process regression, time-delay embedding},
	pages = {964--973},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/S7UQYD7K/faf.html:text/html}
}

@article{clark2004,
	title = {Population {time} {series}: {process} {variability}, {observation} {errors}, {missing} {values}, {lags}, and {hidden} {states}},
	volume = {85},
	copyright = {© 2004 by the Ecological Society of America},
	issn = {1939-9170},
	shorttitle = {Population {Time} {Series}},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/03-0520},
	doi = {https://doi.org/10.1890/03-0520},
	abstract = {Population sample data are complex; inference and prediction require proper accommodation of not only the nonlinear interactions that determine the expected future abundance, but also the stochasticity inherent in data and variable (often unobserved) environmental factors. Moreover, censuses may occur sporadically, and observation errors change with sample methods and effort. The state variable (usually density or abundance) may be hidden from view and known only through highly indirect observational schemes (such as public health records, hunting reports, or fossil/archeological surveys). We extend the basic state-space model for time-series analysis to accommodate these dominant sources of variability that influence population data. Using examples, we show how different types of process error and observation error, unequal sample intervals, and missing values can be accounted for within the flexible framework of Bayesian state-space models. We provide algorithms based on Gibbs sampling that can be used to obtain posterior estimates of population states and of model parameters. For models that can be linearized, results can be used for direct sampling of the posterior, including those with missing values and unequal sample intervals. For nonlinear models, we make use of Metropolis-Hastings within the Gibbs sampling framework. Examples derive from long-term census and population data. We illustrate the extension to discrete state variables with multiple stages using a Time-series Susceptible–Infected–Recovered (TSIR) model for mid 20th-century measles infection in London, where birth rates are assumed known, but susceptibles and infected individuals arise from imperfect reporting.},
	language = {en},
	number = {11},
	urldate = {2020-12-18},
	journal = {Ecology},
	author = {Clark, James S. and Bjørnstad, Ottar N.},
	year = {2004},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1890/03-0520},
	keywords = {Bayesian analysis, time-series analysis, observation error, state-space model, fossil pollen, measles, population regulation, stochasticity},
	pages = {3140--3150},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/V8ZTLWIP/03-0520.html:text/html;Submitted Version:/Users/eric.ward/Zotero/storage/5GUXNG2L/Clark and Bjørnstad - 2004 - Population Time Series Process Variability, Obser.pdf:application/pdf}
}

@article{roberts2013,
	title = {Gaussian processes for time-series modelling},
	volume = {371},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsta.2011.0550},
	doi = {10.1098/rsta.2011.0550},
	abstract = {In this paper, we offer a gentle introduction to Gaussian processes for time-series data analysis. The conceptual framework of Bayesian modelling for time-series data is discussed and the foundations of Bayesian non-parametric modelling presented for Gaussian processes. We discuss how domain knowledge influences design of the Gaussian process models and provide case examples to highlight the approaches.},
	number = {1984},
	urldate = {2020-12-18},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Roberts, S. and Osborne, M. and Ebden, M. and Reece, S. and Gibson, N. and Aigrain, S.},
	month = feb,
	year = {2013},
	note = {Publisher: Royal Society},
	pages = {20110550},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/PRAC4NQS/Roberts et al. - 2013 - Gaussian processes for time-series modelling.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/X7AMSF7B/rsta.2011.html:text/html}
}

@article{hovel2016,
author = {Hovel, Rachel A. and Carlson, Stephanie M. and Quinn, Thomas P.},
title = {Climate change alters the reproductive phenology and investment of a lacustrine fish, the three-spine stickleback},
journal = {Global Change Biology},
volume = {23},
number = {6},
pages = {2308-2320},
keywords = {boreal lake, climate change, growth, ice breakup, lacustrine fish, phenology, reproduction, three-spine stickleback, water temperature},
doi = {https://doi.org/10.1111/gcb.13531},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/gcb.13531},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/gcb.13531},
year = {2017}
}

@article{auger-methe2020,
	title = {A guide to state-space modeling of ecological time series},
	url = {http://arxiv.org/abs/2002.02001},
	abstract = {State-space models (SSMs) are an important modeling framework for analyzing ecological time series. These hierarchical models are commonly used to model population dynamics, animal movement, and capture-recapture data, and are now increasingly being used to model other ecological processes. SSMs are popular because they are flexible and they model the natural variation in ecological processes separately from observation error. Their flexibility allows ecologists to model continuous, count, binary, and categorical data with linear or nonlinear processes that evolve in discrete or continuous time. Modeling the two sources of stochasticity separately allows researchers to differentiate between biological variation (e.g., in birth processes) and imprecision in the sampling methodology, and generally provides better estimates of the ecological quantities of interest than if only one source of stochasticity is directly modeled. Since the introduction of SSMs, a broad range of fitting procedures have been proposed. However, the variety and complexity of these procedures can limit the ability of ecologists to formulate and fit their own SSMs. We provide the knowledge for ecologists to create SSMs that are robust to common, and often hidden, estimation problems, and the model selection and validation tools that can help them assess how well their models fit their data. In this paper, we present a review of SSMs that will provide a strong foundation to ecologists interested in learning about SSMs, introduce new tools to veteran SSM users, and highlight promising research directions for statisticians interested in ecological applications. The review is accompanied by an in-depth tutorial that demonstrates how SSMs models can be fitted and validated in R. Together, the review and tutorial present an introduction to SSMs that will help ecologists to formulate, fit, and validate their models.},
	urldate = {2020-12-19},
	journal = {arXiv:2002.02001},
	author = {Auger-Méthé, Marie and Newman, Ken and Cole, Diana and Empacher, Fanny and Gryba, Rowenna and King, Aaron A. and Leos-Barajas, Vianney and Flemming, Joanna Mills and Nielsen, Anders and Petris, Giovanni and Thomas, Len},
	month = nov,
	year = {2020},
	note = {arXiv: 2002.02001},
	keywords = {Statistics - Methodology, Quantitative Biology - Populations and Evolution, Quantitative Biology - Quantitative Methods},
	file = {arXiv Fulltext PDF:/Users/eric.ward/Zotero/storage/966FWJPG/Auger-Méthé et al. - 2020 - A guide to state-space modeling of ecological time.pdf:application/pdf;arXiv.org Snapshot:/Users/eric.ward/Zotero/storage/WTHNP4YM/2002.html:text/html}
}

@article{pedersen2019,
	title = {Hierarchical generalized additive models in ecology: an introduction with mgcv},
	volume = {7},
	issn = {2167-8359},
	shorttitle = {Hierarchical generalized additive models in ecology},
	url = {https://peerj.com/articles/6876},
	doi = {10.7717/peerj.6876},
	abstract = {In this paper, we discuss an extension to two popular approaches to modeling complex structures in ecological data: the generalized additive model (GAM) and the hierarchical model (HGLM). The hierarchical GAM (HGAM), allows modeling of nonlinear functional relationships between covariates and outcomes where the shape of the function itself varies between different grouping levels. We describe the theoretical connection between HGAMs, HGLMs, and GAMs, explain how to model different assumptions about the degree of intergroup variability in functional response, and show how HGAMs can be readily fitted using existing GAM software, the mgcv package in R. We also discuss computational and statistical issues with fitting these models, and demonstrate how to fit HGAMs on example data. All code and data used to generate this paper are available at: github.com/eric-pedersen/mixed-effect-gams.},
	language = {en},
	urldate = {2020-12-19},
	journal = {PeerJ},
	author = {Pedersen, Eric J. and Miller, David L. and Simpson, Gavin L. and Ross, Noam},
	month = may,
	year = {2019},
	note = {Publisher: PeerJ Inc.},
	pages = {e6876},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/P8RIP7IK/Pedersen et al. - 2019 - Hierarchical generalized additive models in ecolog.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/ZUW7X4RG/6876.html:text/html}
}

@article{holan2018,
	title = {Time series clustering and classification via frequency domain methods},
	volume = {10},
	copyright = {© 2018 Wiley Periodicals, Inc.},
	issn = {1939-0068},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/wics.1444},
	doi = {https://doi.org/10.1002/wics.1444},
	abstract = {Technological innovations combined with various scientific inquiries have resulted in a broad array of classification and clustering applications. Many of these applications directly involve classifying or clustering time series and have leveraged recent methodological advances within the frequency (spectral) domain. This paper reviews methods for clustering/classifying time series in the frequency domain and, in particular, describes various methods for different types of time series ranging from linear and stationary to nonlinear and nonstationary. Our perspective is cast from the statistics/data science literature and does not migrate into the literature on signal processing. Finally, we also summarize various aspects related to implementation, thereby providing the necessary context for interested practitioners. This article is categorized under: Statistical Models {\textgreater} Time Series Models Statistical Learning and Exploratory Methods of the Data Sciences {\textgreater} Clustering and Classification Data: Types and Structure {\textgreater} Time Series, Stochastic Processes, and Functional Data Statistical and Graphical Methods of Data Analysis {\textgreater} Bayesian Methods and Theory},
	language = {en},
	number = {6},
	urldate = {2020-12-19},
	journal = {WIREs Computational Statistics},
	author = {Holan, Scott H. and Ravishanker, Nalini},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1444},
	keywords = {Bayesian, bispectrum, BSLEX, functional data, nonlinear, nonstationary, spectral density, spectrogram, time–frequency},
	pages = {e1444},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/GPHRF5EX/wics.html:text/html}
}

@article{disalvo2013,
	series = {Flank instability at {Mt}. {Etna}},
	title = {Multivariate time series clustering on geophysical data recorded at {Mt}. {Etna} from 1996 to 2003},
	volume = {251},
	issn = {0377-0273},
	url = {http://www.sciencedirect.com/science/article/pii/S0377027312000443},
	doi = {10.1016/j.jvolgeores.2012.02.007},
	abstract = {Time series clustering is an important task in data analysis issues in order to extract implicit, previously unknown, and potentially useful information from a large collection of data. Finding useful similar trends in multivariate time series represents a challenge in several areas including geophysics environment research. While traditional time series analysis methods deal only with univariate time series, multivariate time series analysis is a more suitable approach in the field of research where different kinds of data are available. Moreover, the conventional time series clustering techniques do not provide desired results for geophysical datasets due to the huge amount of data whose sampling rate is different according to the nature of signal. In this paper, a novel approach concerning geophysical multivariate time series clustering is proposed using dynamic time series segmentation and Self Organizing Maps techniques. This method allows finding coupling among trends of different geophysical data recorded from monitoring networks at Mt. Etna spanning from 1996 to 2003, when the transition from summit eruptions to flank eruptions occurred. This information can be used to carry out a more careful evaluation of the state of volcano and to define potential hazard assessment at Mt. Etna.},
	language = {en},
	urldate = {2020-12-20},
	journal = {Journal of Volcanology and Geothermal Research},
	author = {Di Salvo, Roberto and Montalto, Placido and Nunnari, Giuseppe and Neri, Marco and Puglisi, Giuseppe},
	month = feb,
	year = {2013},
	keywords = {Data mining, Etna, Features extraction, Self-Organizing Maps, Summit and flank eruptions, Time series clustering},
	pages = {65--74}
}

@article{liao2005,
	title = {Clustering of time series data—a survey},
	volume = {38},
	issn = {0031-3203},
	url = {http://www.sciencedirect.com/science/article/pii/S0031320305001305},
	doi = {10.1016/j.patcog.2005.01.025},
	abstract = {Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research.},
	language = {en},
	number = {11},
	urldate = {2020-12-20},
	journal = {Pattern Recognition},
	author = {Liao, T. Warren},
	month = nov,
	year = {2005},
	keywords = {Data mining, Clustering, Distance measure, Time series data},
	pages = {1857--1874},
	file = {ScienceDirect Snapshot:/Users/eric.ward/Zotero/storage/QPT98CRA/S0031320305001305.html:text/html}
}

@article{sarda-espinosa2019,
	title = {Time-{series} {clustering} in {R} {using} the dtwclust {package}},
	volume = {11},
	issn = {2073-4859},
	url = {https://journal.r-project.org/archive/2019/RJ-2019-023/index.html},
	language = {en},
	number = {1},
	urldate = {2020-12-20},
	journal = {The R Journal},
	author = {Sardá-Espinosa, Alexis},
	year = {2019},
	pages = {22--43},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/WCLEVBBW/index.html:text/html}
}

@article{cherif2011,
	series = {Adaptive {Incremental} {Learning} in {Neural} {Networks}},
	title = {{SOM} time series clustering and prediction with recurrent neural networks},
	volume = {74},
	issn = {0925-2312},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231211000439},
	doi = {10.1016/j.neucom.2010.11.026},
	abstract = {Local models for regression have been the focus of a great deal of attention in the recent years. They have been proven to be more efficient than global models especially when dealing with chaotic time series. Many models have been proposed to cluster time series and they have been combined with several predictors. This paper presents an extension for recurrent neural networks applied to local models and a discussion about the obtained results.},
	language = {en},
	number = {11},
	urldate = {2020-12-20},
	journal = {Neurocomputing},
	author = {Cherif, Aymen and Cardot, Hubert and Boné, Romuald},
	month = may,
	year = {2011},
	keywords = {Back Propagation Through Time, Local approaches, Recurrent neural network, Self-Organizing Map, Time series prediction},
	pages = {1936--1944},
	file = {ScienceDirect Snapshot:/Users/eric.ward/Zotero/storage/QXJNLDC6/S0925231211000439.html:text/html}
}

@article{moser2001,
	title = {The {CalCOFI} {ichthyoplankton} time series: potential contributions to the management of rocky-shore fishes},
	volume = {42},
	abstract = {Harvest of nearshore fishes off California, particularly species in the recently expanded live-fish fishery, has impacted inany of these stocks. Important taxa are cabezon, sheephead, lingcod, greenlings, and the rockfishes included in the subgenus Pteropodus. Life-history information and fishery-independent abundance indices are badly needed for the development of management strategies for these stocks. The California Cooperative Oceanic Fisheries Investigations (CalCOFI) surveys can provide indices of abundance for larval stages of many species, including cabezon, sheephead, kelp and sand basses, lingcod, and several species of rockfishes. This paper presents, as examples, data on the distribution and abundance of cabezon, sheephead, and Paralahrax (kelp and sand bass) larvae in the Southern California Bight region and compares these with data froni other nearshore ichthyoplankton surveys conducted in the region. Trends in landings for cabezon generally match trends in CalCOFI larval indices, supporting use of the larval catch data as fishery-independent abundance indices. The principal recommendation for improving nearshore larval time series is to reestablish plankton tow stations on CalCOFI survey cruises off central California, where standard plankton tows have not been taken since the survey area was reduced in 1985.},
	language = {en},
	author = {Moser, H Geoffrey and Charter, Richakii L and Watson, William and Amurose, A and Smith, Paul E and Sani, Elaine M and Charter, Sharon R},
	year = {2001},
	pages = {17},
	file = {Moser et al. - 2001 - THE CALCOFI ICHTHYOPLANKTONTIME SERIES POTENTIAL .pdf:/Users/eric.ward/Zotero/storage/HBT2WEVH/Moser et al. - 2001 - THE CALCOFI ICHTHYOPLANKTONTIME SERIES POTENTIAL .pdf:application/pdf}
}

@techreport{maccall2003,
	address = {Portland, OR},
	title = {Status of {Bocaccio} off {California} in 2003. {In} {appendix} to the status of the {Pacific} coast groundfish fishery through 2003: {Stock} assessment and fishery evaluation},
	institution = {Pacific Fishery Management Council},
	author = {MacCall, Alec D.},
	year = {2003}
}

@article{warlick2018,
	title = {History of the {West} {Coast} groundfish trawl fishery {tracking} socioeconomic characteristics across different management policies in a multispecies fishery},
	volume = {93},
	doi = {10.1016/j.marpol.2018.03.014},
	journal = {Marine Policy},
	author = {Warlick, Amanda and Steiner, Erin and Guldin, Marie},
	month = jul,
	year = {2018},
	pages = {9--21}
}

@book{harvey2018b,
	title = {Ecosystem {status} {report} of the {California} {Current} for 2018: {a} {summary} of {ecosystem} {indicators} {compiled} by the {California} {Current} {Integrated} {Ecosystem} {Assessment} {Team} ({CCIEA})},
	shorttitle = {Ecosystem {Status} {Report} of the {California} {Current} for 2018},
	author = {Harvey, Chris and Garfield, Newell and Williams, Gregory and Tolimieri, Nick and Schroeder, Isaac and Hazen, Elliott and Andrews, Kelly and Barnas, Katie and Bograd, Steven and Brodeur, Richard and Burke, Brian and Cope, Jason and deWitt, Lynn and Field, John and Fisher, Jennifer and Good, Thomas and Greene, Correigh and Holland, Daniel and Hunsicker, Mary and Zador, Stephani},
	month = dec,
	year = {2018},
	doi = {10.25923/mvhf-yk36},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/LGM8E4Y5/Harvey et al. - 2018 - Ecosystem Status Report of the California Current .pdf:application/pdf}
}

@article{mcclatchie2008,
	title = {The state of the {California} {Current}, 2007-2008: {La} {Niña} conditions and their effects on the ecosystem},
	volume = {49},
	shorttitle = {The state of the {California} {Current}, 2007-2008},
	abstract = {The state of the California Current system (CCS) between Oregon and Baja California is summarized in this report, covering spring of 2007 to winter/spring 2008. The 2006-07 period began with moderate El Niño conditions which decayed rapidly in early 2007. By summer 2007, a moderate-to-strong La Niña had developed. The North Pacific sea surface temperature (SST) anomalies displayed a negative pattern of Pacific Decadal Oscillation with below-normal SSTs in the California Current and Gulf of Alaska consistent with this pattern. The region experienced anomalously strong southward coastal winds, leading to positive anomalies of the West Coast upwelling index, in strong contrast with 2005. The 2007 upwelling season also began early (in contrast to delayed onset in 2005 and 2006) and remained unseasonably strong through May.The cumulative upwelling for the 2007 season was greater than normal in the southern portion of the California Current system. Despite the La Niña conditions, nitrate and chlorophyll concentrations off Oregon were about average in 2007.On the other hand, copepod biomass rebounded strongly in 2006 after the exceptionally low biomass in 2005, and copepod species richness in 2006 was low, also indicating transport of sub-arctic water into the northern California Current in 2006-07, which is relatively productive but low in diversity. Anomalously high salinities at 200 m depth were also observed during CalCOFI and IMECOCAL cruises off southern and Baja California. In the CalCOFI area,where there has been a general trend toward a deepening mixed layer, the mixed layer responded to this year's La Niña conditions by shoaling.Nitrate (but not silicate and phosphate) concentrations in the mixed layer were anomalously high, but chlorophyll concentrations were about average, except for spring 2007, which was one of the lowest values on record. Spring chlorophyll a concentrations are notably variable during La Niñas. In the northern California Current, forage fish and predatory fish abundance remained low in 2007. In the southern California Current, Pacific sardine (Sardinops sagax) larval abundance was relatively high and distributed in relation to the inner edge of the California Current and the edge of an eddy. Northern anchovy (Engraulis mordax) larvae were relatively low in abundance, apparently related to a large downwelling feature.Reproductive success of all six seabirds monitored on Farallon Island was recovering slowly this year, following the previous two disastrous seasons.However, cluster analysis indicated that reproductive success is still relatively low.The cold-water planktivorous auklets (Ptychoramphus aleuticus) continued to be found at high densities in southern waters. Overall, the transition in 2007 to La Niña conditions appeared to contribute to average to above average pro-ductivity in the California Current, but the physical, chemical, and biological (phytoplankton, zooplankton, fish, and seabird) indices of productivity were far from consistent.},
	journal = {California Cooperative Oceanic Fisheries Investigations Reports},
	author = {Mcclatchie, Sam and Goericke, Ralf and Koslow, J. and Schwing, Frank and Bograd, Steven and Charter, Richard and Watson, William and Lo, Nancy and Hill, Kevin and Gottschalck, Jon and L'Heureux, Michelle and Xue, Yan and Peterson, William and Emmett, R.T. and Collins, Curtis and Gaxiola-Castro, Gilberto and Durazo, Reginaldo and Kahru, Mati and Mitchell, B. and Bjorkstedt, Eric},
	month = nov,
	year = {2008},
	pages = {39--76}
}

@article{ward2010c,
	title = {Inferring spatial structure from time-series data: using multivariate state-space models to detect metapopulation structure of {California} sea lions in the {Gulf} of {California}, {Mexico}},
	volume = {47},
	copyright = {© 2009 The Authors. Journal compilation © 2009 British Ecological Society},
	issn = {1365-2664},
	shorttitle = {Inferring spatial structure from time-series data},
	url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2664.2009.01745.x},
	doi = {https://doi.org/10.1111/j.1365-2664.2009.01745.x},
	abstract = {1. Understanding spatial structure and identifying subpopulations are critical for estimating population growth rates and extinction risk, and as such essential for effective conservation planning. However, movement and spatiotemporal environmental data are often unavailable, limiting our ability to directly define subpopulations and their level of asynchrony. 2. This study applies a recently developed statistical technique using time-series analysis of abundance data to identify subpopulations. The approach uses multivariate state-space models and Akaike’s Information Criterion-based model selection to quantify the data support for different subpopulation numbers and configurations. This technique is applied to the population of California sea lions Zalophus californianus in the Gulf of California, Mexico, distributed across 13 breeding sites. 3. The abundance of California sea lions in the Gulf of California has declined over the last decade, though not all areas have been equally affected. In light of this variation, it is important to understand the population structure to ensure accurate viability assessments and effective management. 4. Our data support the hypothesis that the Gulf of California sea lion population has four subpopulations, each with 2–5 breeding sites. The dynamics between several adjacent subpopulations were correlated, suggesting that they experience similar environmental variation. For each subpopulation, we estimated long-term growth rates, as well as the environmental and observation variation. 5. For most of the subpopulations, our estimates of growth rates were considerably lower than those previously reported. In addition, we found considerable variability across subpopulations in their projected risk of severe decline over the next 50 years. 6. Synthesis and applications. We illustrate a new multivariate state-space modelling technique that uses time series of abundance to quantify the data support for different subpopulation configurations. Our analysis of the California sea lion population in the Gulf of California indicates that the population is spatially structured into four subpopulations, each exhibiting distinct risks of extinction. Based on our results, we recommend that conservation and management efforts in the Gulf of California focus on the two subpopulations with high probabilities of extinction within the next 50 years (Northern Midriff, Southern Midriff). Multivariate state-space models provide a practical approach to determine the spatial structure of virtually any species; they may be particularly useful for species of conservation concern for which data on dispersal and environmental drivers are likely to be scarce.},
	language = {en},
	number = {1},
	urldate = {2020-12-21},
	journal = {Journal of Applied Ecology},
	author = {Ward, Eric J. and Chirakkal, Haridas and González‐Suárez, Manuela and Aurioles‐Gamboa, David and Holmes, Elizabeth E. and Gerber, Leah},
	year = {2010},
	note = {\_eprint: https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2664.2009.01745.x},
	keywords = {Zalophus californianus, metapopulation, extinction risk, multivariate state-space, spatial structure, stochastic growth rate},
	pages = {47--56},
	file = {Full Text PDF:/Users/eric.ward/Zotero/storage/HNAPUKV9/Ward et al. - 2010 - Inferring spatial structure from time-series data.pdf:application/pdf;Snapshot:/Users/eric.ward/Zotero/storage/V287ZAXT/j.1365-2664.2009.01745.html:text/html}
}

@techreport{holmes2020,
	title = {Analysis of multivariate time-series using the {MARSS} package. \url{https://cran.r-project.org/web/packages/MARSS/vignettes/UserGuide.pdf}},
	note = {https://cran.r-project.org/web/packages/MARSS/vignettes/UserGuide.pdf},
	author = {Holmes, E. E. and Ward, E. J. and Scheuerell, M. D.},
	year = {2020}
}

@article{carpenter2017a,
author = {Bob Carpenter and Andrew Gelman and Matthew D. Hoffman and Daniel Lee and Ben Goodrich and Michael Betancourt and Marcus Brubaker and Jiqiang Guo and Peter Li and Allen Riddell},
   title = {Stan: A Probabilistic Programming Language},
   journal = {Journal of Statistical Software},
   volume = {76},
   number = {1},
   year = {2017},
   issn = {1548-7660},
   pages = {1--32},
   doi = {10.18637/jss.v076.i01},
   url = {https://www.jstatsoft.org/v076/i01}
}

@Manual{chamberlain2020,
    title = {rerddap: General Purpose Client for `ERDDAP' Servers},
    author = {Scott Chamberlain},
    year = {2020},
    note = {R package version 0.7.0},
    url = {https://CRAN.R-project.org/package=rerddap},
}

@techreport{rcoreteam2020,
	address = {Vienna, Austria},
	type = {manual},
	title = {R: {a} language and environment for statistical computing},
	url = {https://www.R-project.org/},
	author = {{R Core Team}},
	year = {2020},
	note = {tex.organization: R Foundation for Statistical Computing}
}

@techreport{rcoreteam2019b,
	address = {Vienna, Austria},
	type = {manual},
	title = {R: {a} language and environment for statistical computing},
	url = {https://www.R-project.org/},
	author = {{R Core Team}},
	year = {2019},
	note = {tex.organization: R Foundation for Statistical Computing}
}

@article{vehtari2017,
	title = {Practical {Bayesian} model evaluation using leave-one-out cross-validation and {WAIC}},
	volume = {27},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-016-9696-4},
	doi = {10.1007/s11222-016-9696-4},
	abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
	language = {en},
	number = {5},
	urldate = {2020-12-21},
	journal = {Statistics and Computing},
	author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
	month = sep,
	year = {2017},
	pages = {1413--1432},
	file = {Submitted Version:/Users/eric.ward/Zotero/storage/G6YQEMKI/Vehtari et al. - 2017 - Practical Bayesian model evaluation using leave-on.pdf:application/pdf}
}

@book{gelman2013BDA,
  title={Bayesian data analysis, third edition},
  author={Gelman, Andrew and Carlin, John B and Stern, Hal S and Dunson, David B and Vehtari, Aki and Rubin, Donald B},
  year={2013},
  publisher={CRC press}
}

@article{vehtari2020,
	title = {loo: {Efficient} leave-one-out cross-validation and {WAIC} for {Bayesian} models},
	url = {https://mc-stan.org/loo/},
	author = {Vehtari, Aki and Gabry, Jonah and Magnusson, Mans and Yao, Yuling and Bürkner, Paul-Christian and Paananen, Topi and Gelman, Andrew},
	year = {2020}
}

@article{gelman1992c,
	title = {Inference from {iterative} {simulation} {using} {multiple} {sequences}},
	volume = {7},
	issn = {0883-4237},
	url = {https://www.jstor.org/stable/2246093},
	abstract = {The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were continued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normality after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random-effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.},
	number = {4},
	urldate = {2020-12-21},
	journal = {Statistical Science},
	author = {Gelman, Andrew and Rubin, Donald B.},
	year = {1992},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {457--472}
}

@article{latimer2009b,
	title = {Hierarchical models facilitate spatial analysis of large data sets: a case study on invasive plant species in the northeastern {United} {States}},
	volume = {12},
	copyright = {© 2008 Blackwell Publishing Ltd/CNRS},
	issn = {1461-0248},
	shorttitle = {Hierarchical models facilitate spatial analysis of large data sets},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1461-0248.2008.01270.x},
	doi = {https://doi.org/10.1111/j.1461-0248.2008.01270.x},
	abstract = {Many critical ecological issues require the analysis of large spatial point data sets – for example, modelling species distributions, abundance and spread from survey data. But modelling spatial relationships, especially in large point data sets, presents major computational challenges. We use a novel Bayesian hierarchical statistical approach, ‘spatial predictive process’ modelling, to predict the distribution of a major invasive plant species, Celastrus orbiculatus, in the northeastern USA. The model runs orders of magnitude faster than traditional geostatistical models on a large data set of c. 4000 points, and performs better than generalized linear models, generalized additive models and geographically weighted regression in cross-validation. We also use this approach to model simultaneously the distributions of a set of four major invasive species in a spatially explicit multivariate model. This multispecies analysis demonstrates that some pairs of species exhibit negative residual spatial covariation, suggesting potential competitive interaction or divergent responses to unmeasured factors.},
	language = {en},
	number = {2},
	urldate = {2020-12-24},
	journal = {Ecology Letters},
	author = {Latimer, A. M. and Banerjee, S. and Jr, H. Sang and Mosher, E. S. and Jr, J. A. Silander},
	year = {2009},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1461-0248.2008.01270.x},
	keywords = {Bayesian, computational limitation, invasive species, multivariate spatial models, point-referenced, spatial modelling, spatial predictive process, species distributions},
	pages = {144--154},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/A5HKU57C/j.1461-0248.2008.01270.html:text/html}
}

@article{kimeldorf1970a,
	title = {A {correspondence} {between} {Bayesian} {estimation} on {stochastic} {processes} and {smoothing} by {splines}},
	volume = {41},
	issn = {0003-4851},
	url = {https://www.jstor.org/stable/2239347},
	number = {2},
	urldate = {2020-12-26},
	journal = {The Annals of Mathematical Statistics},
	author = {Kimeldorf, George S. and Wahba, Grace},
	year = {1970},
	note = {Publisher: Institute of Mathematical Statistics},
	pages = {495--502}
}

@incollection{hastie1992,
	title = {Statistical {models} in {S}},
	publisher = {Wadsworth \& Brooks/Cole},
	author = {Hastie, T. J.},
	editor = {Chambers, J. M. and Hastie, T. J.},
	year = {1992},
	note = {Section: Generalized linear models}
}

@article{knape2008a,
	title = {Estimability of {density} {dependence} in {models} of {time} {series} {data}},
	volume = {89},
	copyright = {© 2008 by the Ecological Society of America},
	issn = {1939-9170},
	url = {https://esajournals.onlinelibrary.wiley.com/doi/abs/10.1890/08-0071.1},
	doi = {https://doi.org/10.1890/08-0071.1},
	abstract = {Estimation of density dependence from time series data on population abundance is hampered in the presence of observation or measurement errors. Fitting state–space models has been proposed as a solution that reduces the bias in estimates of density dependence caused by ignoring observation errors. While this is often true, I show that, for specific parameter values, there are identifiability issues in the linear state–space model when the strength of density dependence and the observation and process error variances are all unknown. Using simulation to explore properties of the estimators, I illustrate that, unless assumptions are imposed on the process or observation error variances, the variance of the estimator of density dependence varies critically with the strength of the density dependence. Under compensatory dynamics, the stronger the density dependence the more difficult it is to estimate in the presence of observation errors. The identifiability issues disappear when density dependence is estimated from the state–space model with the observation error variance known to the correct value. Direct estimates of observation variance in abundance censuses could therefore prove helpful in estimating density dependence but care needs to be taken to assess the uncertainty in variance estimates.},
	language = {en},
	number = {11},
	urldate = {2020-12-27},
	journal = {Ecology},
	author = {Knape, Jonas},
	year = {2008},
	note = {\_eprint: https://esajournals.onlinelibrary.wiley.com/doi/pdf/10.1890/08-0071.1},
	keywords = {density dependence, state–space models, time series analysis},
	pages = {2994--3000},
	file = {Snapshot:/Users/eric.ward/Zotero/storage/G7FQNX9V/08-0071.html:text/html}
}

@article{burkner2020a,
	title = {Approximate leave-future-out cross-validation for {Bayesian} time series models},
	volume = {90},
	issn = {0094-9655, 1563-5163},
	url = {http://arxiv.org/abs/1902.06281},
	doi = {10.1080/00949655.2020.1783262},
	abstract = {One of the common goals of time series analysis is to use the observed series to inform predictions for future observations. In the absence of any actual new data to predict, cross-validation can be used to estimate a model's future predictive accuracy, for instance, for the purpose of model comparison or selection. Exact cross-validation for Bayesian models is often computationally expensive, but approximate cross-validation methods have been developed, most notably methods for leave-one-out cross-validation (LOO-CV). If the actual prediction task is to predict the future given the past, LOO-CV provides an overly optimistic estimate because the information from future observations is available to influence predictions of the past. To properly account for the time series structure, we can use leave-future-out cross-validation (LFO-CV). Like exact LOO-CV, exact LFO-CV requires refitting the model many times to different subsets of the data. Using Pareto smoothed importance sampling, we propose a method for approximating exact LFO-CV that drastically reduces the computational costs while also providing informative diagnostics about the quality of the approximation.},
	number = {14},
	urldate = {2020-12-27},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Bürkner, Paul-Christian and Gabry, Jonah and Vehtari, Aki},
	month = sep,
	year = {2020},
	note = {arXiv: 1902.06281},
	keywords = {Statistics - Methodology},
	pages = {2499--2523},
	file = {arXiv Fulltext PDF:/Users/eric.ward/Zotero/storage/NHN9TWJU/Bürkner et al. - 2020 - Approximate leave-future-out cross-validation for .pdf:application/pdf;arXiv.org Snapshot:/Users/eric.ward/Zotero/storage/2EY3RRRB/1902.html:text/html}
}

@techreport{pfmc2020,
	address = {Portland, OR},
	title = {Status of the {Pacific} {Coast} {Groundfish} {Fishery}: {Stock} {Assessment} and {Fishery} {Evaluation}},
	institution = {The Pacific Fishery Management Council},
	author = {PFMC},
	month = sep,
	year = {2020}
}


@article{paananen2021,
	title = {Implicitly adaptive importance sampling},
	volume = {31},
	issn = {1573-1375},
	url = {https://doi.org/10.1007/s11222-020-09982-2},
	doi = {10.1007/s11222-020-09982-2},
	abstract = {Adaptive importance sampling is a class of techniques for finding good proposal distributions for importance sampling. Often the proposal distributions are standard probability distributions whose parameters are adapted based on the mismatch between the current proposal and a target distribution. In this work, we present an implicit adaptive importance sampling method that applies to complicated distributions which are not available in closed form. The method iteratively matches the moments of a set of Monte Carlo draws to weighted moments based on importance weights. We apply the method to Bayesian leave-one-out cross-validation and show that it performs better than many existing parametric adaptive importance sampling methods while being computationally inexpensive.},
	language = {en},
	number = {2},
	urldate = {2021-03-24},
	journal = {Statistics and Computing},
	author = {Paananen, Topi and Piironen, Juho and Bürkner, Paul-Christian and Vehtari, Aki},
	month = feb,
	year = {2021},
	pages = {16},
	file = {Springer Full Text PDF:/Users/eric.ward/Zotero/storage/83D3DXHV/Paananen et al. - 2021 - Implicitly adaptive importance sampling.pdf:application/pdf}
}

@Book{mgcvbook,
  title = {Generalized additive models: an introduction with {R}},
  year = {2017},
  author = {S.N Wood},
  edition = {2},
  publisher = {Chapman and Hall/CRC},
}

@article{eilers1996,
  title = {Flexible smoothing with {B}-splines and penalties},
  author = {Eilers, Paul H. C. and Marx, Brian D.},
  year = {1996},
  volume = {11},
  pages = {89--102},
  publisher = {Institute of Mathematical Statistics},
  journal = {Statist. Sci.},
  number = {2}
}

@article{simpson2017,
  title = {Penalising model component complexity: a principled, practical approach to constructing priors},
  author = {Simpson, Daniel and Rue, H{\aa}vard and Riebler, Andrea and Martins, Thiago G. and S{\o}rbye, Sigrunn H.},
  year = {2017},
  volume = {32},
  pages = {1--28},
  publisher = {{Institute of Mathematical Statistics}},
  doi = {10.1214/16-STS576},
  journal = {Statist. Sci.},
  number = {1}
}

@article{eilers2010,
author = {Eilers, Paul H. C. and Marx, Brian D.},
title = {Splines, knots, and penalties},
journal = {WIREs Computational Statistics },
volume = {2},
number = {6},
pages = {637-653},
keywords = {P-splines, truncated power functions, difference penalty, interpolation, smoothing},
doi = {https://doi.org/10.1002/wics.125},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.125},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wics.125},
abstract = {Abstract Penalized splines have gained much popularity as a flexible tool for smoothing and semi-parametric models. Two approaches have been advocated: (1) use a B-spline basis, equally spaced knots, and difference penalties [Eilers PHC, Marx BD. Flexible smoothing using B-splines and penalized likelihood (with Comments and Rejoinder). Stat Sci 1996, 11:89–121.] and (2) use truncated power functions, knots based on quantiles of the independent variable and a ridge penalty [Ruppert D, Wand MP, Carroll RJ. Semiparametric Regression. New York: Cambridge University Press; 2003]. We compare the two approaches on many aspects: numerical stability, quality of the fit, interpolation/extrapolation, derivative estimation, visual presentation and extension to multidimensional smoothing. We discuss mixed model and Bayesian parallels to penalized regression. We conclude that B-splines with difference penalties are clearly to be preferred. WIREs Comp Stat 2010 2 637–653 DOI: 10.1002/wics.125 This article is categorized under: Statistical and Graphical Methods of Data Analysis > Density Estimation},
year = {2010}
}

@article{crainiceanu2005,
   author = {Ciprian M. Crainiceanu and David Ruppert and Matthew P. Wand},
   title = {Bayesian Analysis for Penalized Spline Regression Using WinBUGS},
   journal = {Journal of Statistical Software, Articles},
   volume = {14},
   number = {14},
   year = {2005},
   keywords = {},
   abstract = {Penalized splines can be viewed as BLUPs in a mixed model framework, which allows the use of mixed model software for smoothing. Thus, software originally developed for Bayesian analysis of mixed models can be used for penalized spline regression. Bayesian inference for nonparametric models enjoys the flexibility of nonparametric models and the exact inference provided by the Bayesian inferential machinery. This paper provides a simple, yet comprehensive, set of programs for the implementation of nonparametric Bayesian analysis in WinBUGS. Good mixing properties of the MCMC chains are obtained by using low-rank thin-plate splines, while simulation times per iteration are reduced employing WinBUGS specific computational tricks.},
   issn = {1548-7660},
   pages = {1--24},
   doi = {10.18637/jss.v014.i14},
   url = {https://www.jstatsoft.org/v014/i14}
}
