---
title: Smoothed factor analysis for multivariate time series
author: Eric J. Ward$^1$ and ...
date: ''
output:
  pdf_document:
    fig_caption: yes
    includes:
      in_header: options.sty
    latex_engine: xelatex
  word_document: default
  html_document: default
  bookdown::pdf_document2:
csl: ecology.csl
bibliography: gpdfa.bib
---

```{r setup, include=FALSE, echo=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy=FALSE, tidy.opts=list(width.cutoff=60), warning = FALSE, message = FALSE)
library(bayesdfa)
library(knitr)
library(tidyverse)
library(ggsidekick)
library(ggrepel)
library(viridis)
library(gridExtra)
library(rstan)
library(ggrepel)
library(cowplot)
```


$^1$Conservation Biology Division, Northwest Fisheries Science Center, National Marine Fisheries Service, National Oceanic and Atmospheric Administration, 2725 Montlake Blvd E, Seattle WA, 98112, USA\

## Abstract
\setlength\parindent{24pt}

## Introduction

Ecological data can be characterized by multiple sources of variability, including stochastic natural variation, and errors associated with data collection (observation, sampling, and measurement errors). Disentangling these sources of variability is often challenging, and necessitates the use of complex statistical methods, including state space models. Such approaches have become ubiquitous in ecology, particularly for time series data [@auger-methe2020] – in part because these models allow researchers to make inferences about ecological processes that aren’t directly observable via corrupted observations. Applications of these models include estimating population change over time [@clark2004], understanding movement dynamics [@patterson2008], and understanding spatiotemporal variation [@anderson2019b].

Estimating multiple sources of variation in state space models is numerically complex, and can be constrained explicitly or implicitly in ecological models via model assumptions. For example, discrete time state-space models of population trajectories generally assume latent population size can be approximated by an autoregressive process in log-space $x_{t+1}=f(x_{t} )+\epsilon_t$, where $x_{t}=log(n_{t})$ and $\epsilon_t$ are normally distributed process deviations representing stochastic variability of the natural system [@dennis2006]. The autoregressive assumption is critical here; without such a constraint, the variance of the stochastic noise $\epsilon_t$ is not estimable in the presence of an observation or data model. If model inference is not dependent on parameters of ecological interest (e.g. growth rates, density dependence), a wide range of alternative semi-parametric approaches exist that can be used to model the trajectory of x_t, including generalized additive models (GAMs, [@wood2011]) and Gaussian process models [@roberts2013]. Because these models are not autoregressive with a constant time step, the 'wiggliness' of the model can be adjusted as part of the model fitting. In addition to their flexibility, these alternative models of $x_{t}$ may be better suited for situations when data are patchily distributed in time or unequally spaced, making estimation of process and observation errors more difficult. 

Challenges posed by univariate time series models also apply to multivariate time series models, though an additional complexity in the multivariate setting is that the number of latent time series may be variable, $k=1,…,m$, where $m$ is the number of time series observed. At one extreme, $k=m$, and each time series can be thought of as corresponding to a unique latent state. Motivating questions for involved in analyzing these kinds of data include estimating correlated latent processes or trends, or estimating effects of environmental covariates [@hovel2016]. At the other extreme, $k=1$, where each time series can be thought of representing multiple measurements of the same trajectory of states, or trend, with optional offsets or coefficients included for each time series (offsets allowing for differing detectability). Applications focused on estimating a single trend from multivariate data include the development of ecological indicators. Models with intermediate numbers of latent states 1<k<m require mapping of time series to latent trends. These may be specified a priori [@ward2010c] or estimated within the modeling framework using dimension reduction techniques. 

Many statistical approaches have been proposed in recent years for clustering or estimating common signals in multivariate time series [@liao2005]. Examples include clustering based on similarities among time series features [@sarda-espinosa2019], identifying common patterns in the frequency domain [@holan2018], and clustering based on neural networks [@cherif2011]. Application of these methods to ecological data has been limited, however, in part because many of these approaches identify clusters from raw data and don’t explicitly account for observation error. An alternative approach that has been used in ecology to map collections of multivariate time series to latent states, while accounting for observation error, is dynamic factor analysis (DFA) [@zuur2003b; @zuur2003c]. DFA is an extension of factor analysis for time series data, and estimates a small number of common trends that can describe observed data. Mapping time series to trends is done via an estimated matrix of factor loadings – these allow each time series to be modeled as a mixture of the estimated latent trends, rather than assigning each time series to a single trend.

The objective of this analysis is to introduce a new class of DFA models for multivariate time series. Just as the univariate autoregressive model described above can be approximated with smooth functions, DFA models may be extended to use smooth functions in lieu of autoregressive processes. Recent work has highlighted the application of hierarchical GAMs for multiple data sources [@pedersen2019]. These approaches are flexible and likely to provide similar inference to DFA for single latent trend, however these methods have not been extended to include more than one process. We illustrate two options for modeling smooth functions for latent trends: basis splines ('b-splines') and Gaussian process models. Both approaches are compared to conventional autoregressive DFA models for two datasets on marine fishes from the west coast of the USA. All data and code are for replicating our analysis are on Github, and in our existing R package 'bayesdfa' [@ward2019].

## Methods

### Dynamic Factor Model  

The basic DFA model can be written as a multivariate state space model, consisting of a latent process model and observation or data model. In its simplest form, the process model is expressed as a random walk, $\textbf{ x }_{ t+1 }=\textbf{ x }_{ t }+\textbf{ w }_{ t }$, where $\textbf{ w }_{ t }\sim MVN(0,\textbf{Q})$. For identifiability constraints [@zuur2003b; @holmes2012b], the covariance matrix $\textbf{Q}$ is generally constrained to be an identity matrix. Additional features may be incorporated into the process model, including autoregressive or moving average coefficients, covariates, or deviations that are more extreme than that of the normal distribution [@ward2019]. The observation model in a DFA is expressed as a linear combination of trends $\textbf{x}_{t}$ and matrix of loadings coefficients $\textbf{Z}$, y_t=〖Zx〗_t+〖Bd_t+e〗_t. In addition to the trends and loadings, time varying covariates $\textbf{d}_t$ may be optionally included and linked to the observations through estimated coefficients $\textbf{B}$. The vector $\textbf{e}_t$ represents residual observation error. These typically are modeled as a diagonal matrix, $\textbf{ e }_{ t }\sim MVN(0,\textbf{R})$ but off-diagonal elements may be estimated [@holmes2020]. Further details of the Bayesian implementation of the DFA model are provided in [@ward2019].

### B-splines  
The DFA model is extremely flexible, but a downside is that the latent process x_t

### Gaussian process
	

### Application: larval fish survey  
As a first application of smooth factor analysis models, we apply DFA to a long term time series of larval fishes collected off California. The California Cooperative Oceanic Fisheries Investigations (CalCOFI) survey has been collecting physical and biological samples since 1949, to monitor annual, seasonal, and spatial changes to the California Current Ecosystem [@bograd2003]. The CalCOFI data has been incorporated into models used to assess population status [@maccall2003], and numerous publications have used time series of larval fishes from the CalCOFI survey as indicators of ecosystem state [@mcclatchie2008]. These types of motivating questions also present an opportunity to apply DFA with both conventional and smoothed trends to summarize ecosystem state indices. For this application, we focus on the dynamics of three species of juvenile rockfishes: Aurora rockfish (*Sebastes aurora*), Shortbelly rockfish (*S. jordani*), and Bocaccio rockfish (*S. paucispinis*). For the purposes of this analysis, we restrict the time series to data collected since 1985, when sampling has been consistent in space and time [@moser2001]. Though CalCOFI cruises are done throughout the year, we are primarily interested in estimating interannual trends, and thus restrict our analysis to considering spring cruises from 1-April to 22-May when densities of most rockfish species are highest [@mosek2000]. All data were retrieved using R software [@rcoreteam2020] and the rerddap package [@chamberlain2020].

With only three time series, we focus on identifying models estimating a single shared trend. Other types of models, including hierarchical GAMs [@pedersen2019] or models allowing estimated offsets may also be useful in this type of application. Where the DFA model differs is that unlike models with random intercepts or additive offset terms, the DFA factor loadings $\textbf{Z}$ are multiplicative and may be close to zero. These cases may arise when a particular time series has a low signal to noise ratio, or if there is low correspondence with the latent trends estimated among all other time series. In addition to estimating a conventional 1-trend DFA model with a latent autoregressive process, we evaluate 1-trend b-spline and GP models. Because we have no a priori hypotheses about the complexity of these smoothed factor models, we evaluated 5 models for each, using 6, 12, 18, 24, and 30 equally spaced knots.

### Application: commercial fisheries landings  

As a slightly more complex example of the smooth factor analysis model, we examine the performance of 2-trend models, using a dataset of commercial fisheries catches from the west coast of the USA. This dataset consists of commercial landings by dominant species, and is reported annually to the Pacific Fishery Management Council (cite SAFE tables). This dataset consists of 13 species or groups reported over a 39 year period (1981 – 2019). Landings on the west coast are dominated by Pacific hake (also Pacific whiting, Merluccius productus), but also include substantial catches of rockfishes (*Sebastes spp.*) and flatfishes (e.g. Dover sole, *Solea solea*). Over the course of the last 4 decades, these species have experienced variability associated with population dynamics and the environment, but the patterns of landings also reflects a dynamic fisheries management process. Examples of changes include temporarily closing areas to fishing to protect species of conservation concern, and implementing catch share programs. These processes, combined with environmental conditions that have been positive for many species have resulted in many increasing populations [@warlick2018]. Given these various management and ecological changes, it is important to summarize patterns of landings, and identify common trends as indicators for management and ecosystem status [@harvey2018b].

As with our previous example, we compared conventional DFA models to those modeling the trends with smooth functions. Preliminary model fitting suggested that 2-trend models were more supported by the data, and thus will be the focus of our analysis. In addition to modeling the 2-trend model with conventional DFA, we evaluated B-spline and Gaussian process models with 6 to 30 equally spaced knots. 

### Estimation and model selection  

We developed our DFA model in a Bayesian framework, using Stan and the package rstan [@standevelopmentteam2016a], which implements Markov chain Monte Carlo (MCMC) using the No-U Turn Sampling (NUTS) algorithm [@hoffman2014; @carpenter2017a]. For each model considered, we ran 3 parallel MCMC chains for 3000 iterations each, discarding the first 50% of the samples. Convergence diagnostics were assessed using summary statistics (R-hat, [@gelman1992c]). Previous approaches have used the Leave One Out Information Criterion (LOOIC) as a model selection tool [@vehtari2017; @vehtari2020]. Preliminary model checks using LOOIC for the models included in our analysis indicated that many models had 1-4 data points that had high Pareto-k statistics (possibly because of model-misspecification or model flexibity; @vehtari2017). As a slower but potentially more robust model selection approach, we implemented k-fold cross validation. There are many possible ways to assign 'folds' in cross-validation, and because of our focus on the temporal aspect of these DFA models, we assigned each year of data to a unique fold. Implementing these models in a Bayesian framework requires significant computational time; instead of fitting each model to a dataset once, a single model is re-fit to a dataset for as many years as there are data (35 years for our application to CalCOFI data; 39 years for our application to commercial landings data). 

## Results

```{r echo=FALSE}
m = readRDS("calcofi_models.rds")
fit = m[[5]]
r = bayesdfa::rotate_trends(fit)
post_means = apply(r$Z_rot,2,mean)
post_low = apply(r$Z_rot,2,quantile,0.025)
post_hi = apply(r$Z_rot,2,quantile,0.975)
```

In our comparison of 1-trend DFA models applied to the three timeseries of juvenile rockfishes, we found that models with smooth trends were better supported over conventional random walk models. In calculating LOOIC, all models had a few (1-3) data points with Pareto-k statistic values between 0.7 - 1, likely because of the flexibility of these models. Across models considered, we found that the B-spline trend model with 24 knots had slightly lower LOOIC values than alternatives, and appeared to capture the dynamics of the three *Sebastes* time series \@ref(fig:fig1). All three species were estimated to have positive loadings on the estimated trend, with shortbelly rockfishes had the highest loading (`r round(post_means[3],2)`, 95% posterior interval = `r round(post_low[3],2)`-`r round(post_hi[3],2)`) followed by aurora (`r round(post_means[1],2)`, 95% posterior interval = `r round(post_low[1],2)`-`r round(post_hi[1],2)`) and bocaccio rokfishes (`r round(post_means[2],2)`, 95% posterior interval = `r round(post_low[2],2)`-`r round(post_hi[2],2)`).

```{r table1, echo=FALSE}
cv = readRDS("calcofi_models_cv.rds")

tab = data.frame("Trend model"=c("Random walk", rep("B-spline",5), rep("Gaussian process",5)), 
  "Knots" = c(NA, rep(seq(6,30,by=6),2)),
  "ELPD" = unlist(lapply(cv,getElement,2)),
  "SE" = unlist(lapply(cv,getElement,3)))
# order table by ascending LOOIC and show tip 5 models
knitr::kable(tab[order(tab$ELPD, decreasing=TRUE)[1:5],])
```

```{r table2, echo=FALSE}
cv = readRDS("landings_models_cv.rds")

tab = data.frame("Trend model"=c("Random walk", rep("B-spline",5), rep("Gaussian process",5)), 
  "Knots" = c(NA, rep(seq(6,30,by=6),2)),
  "ELPD" = unlist(lapply(cv,getElement,2)),
  "SE" = unlist(lapply(cv,getElement,3)))
# order table by ascending LOOIC and show tip 5 models
knitr::kable(tab[order(tab$ELPD, decreasing=TRUE)[1:5],])
```

## Acknowledgments

\break

```{r fig1, echo=FALSE, fig.pos="placeHere", fig.cap="Standardized densities of juvenile rockfish species collected in the CalCOFI survey, and estimates of latent trends for three candidate models. A B-spline model with 24 knots had slighty lower LOOIC values than other B-spline models (such as the more coarse 12 knot model) and the conventional DFA, modeled with a random walk. The posterior mean from each model is shown as a solid black line, and 95% credible intervals are shown in the grey region. \\label{fig:fig1}", fig.height=6}
m = readRDS("calcofi_models.rds")

# standardize raw data
x = readRDS("calcofi_data.rds")
scaled_x = group_by(x, ts) %>%
  dplyr::mutate(obs = (obs-mean(obs))/sd(obs))
scaled_x$Species = c("aurora","shortbelly","bocaccio")[scaled_x$ts]

fit = m[[3]]
r = bayesdfa::rotate_trends(fit)
trend_df1 = data.frame("time"= seq(min(x$time),max(x$time)),
  "low" = c(r$trends_lower),
  "mean"=c(r$trends_mean),
  "hi"=c(r$trends_upper),
  "Model" = "B-spline, 12 knots")

fit = m[[5]]
r = bayesdfa::rotate_trends(fit)
trend_df2 = data.frame("time"= seq(min(x$time),max(x$time)),
  "low" = c(r$trends_lower),
  "mean"=c(r$trends_mean),
  "hi"=c(r$trends_upper),
  "Model" = "B-spline, 24 knots")

fit = m[[1]]
r = bayesdfa::rotate_trends(fit)
trend_df3 = data.frame("time"= seq(min(x$time),max(x$time)),
  "low" = c(r$trends_lower),
  "mean"=c(r$trends_mean),
  "hi"=c(r$trends_upper),
  "Model" = "Random walk")

trend_df = rbind(trend_df1, trend_df2, trend_df3)

g1 = ggplot(trend_df, aes(time,mean)) +
  geom_ribbon(aes(ymin=low,ymax=hi),alpha=0.2) +
  geom_line() +
  theme_bw() +
  facet_wrap(~Model, nrow=3, scale="free_y") + 
  theme(strip.background =element_rect(fill="white")) + 
  geom_point(data=scaled_x, aes(x=time,y=obs,col=Species),alpha=0.7,size=3) +
  scale_color_manual("Species",
    values = c("aurora" = "#440154FF", "shortbelly" = "#2A788EFF", "bocaccio" = "#7AD151FF")) +
  ylab("Trend estimate") +
  xlab("Year")

print(g1)
```

\break  
  
```{r fig2, echo=FALSE, fig.pos="placeHere", fig.cap="Estimated trends from the 2-trend DFA model applied to commercial groundfish landings off the west coast of the United States. The model results with lowest LOOIC is shown, a model that allows trends to be approximated with B-spines (6 knots). The posterior mean for each trend is shown, with ribbons representing 95% credible intervals. \\label{fig:fig4}"}

# make plots for best model
m = readRDS("landings_spline_6.rds")
r = rotate_trends(m)

g1 = plot_trends(r, years = 1981:2019) + 
  theme_bw()
print(g1)
```

\break  

```{r fig3, echo=FALSE, fig.pos="placeHere", fig.cap="Estimated loadings for each species or group from a 2-trend DFA model with latent trends modeled as B-splines. The posterior mean for each species is shown as a point, with lines representing 95% credible intervals. \\label{fig:fig3}"}
# bring in raw data
d = read.csv("data/port_landings_table2.csv", stringsAsFactors = FALSE)
d = dplyr::select(d, -Year)
for(i in 1:ncol(d)) {
  d[,i] = log(as.numeric(d[,i]))
}

# bring in best model
# make plots for best model
m = readRDS("landings_spline_6.rds")
r = rotate_trends(m)

loadings = as.data.frame(cbind(apply(r$Z_rot,c(2,3),mean), apply(r$Z_rot,c(2,3),sd)))
names(loadings) = c("Trend1_mean","Trend2_mean","Trend1_sd","Trend2_sd")
names(d)[1] = "Pacific whiting"
names(d)[4] = "Pacific cod"
names(d)[5] = "Misc roundfish"
names(d)[8] = "Arrowtooth flounder"
names(d)[9:13] = c("Dover sole","English sole","Petrale sole","Misc flatfish","Misc groundfish")
loadings$species = names(d)

g1 = ggplot(dplyr::filter(loadings, species!="Misc roundfish",species!="Misc flatfish",species!="Misc groundfish"),
  aes(Trend1_mean,Trend2_mean,label=species)) +
  geom_point(col="darkblue") +
  geom_errorbar(aes(ymin=Trend2_mean - Trend2_sd,ymax=Trend2_mean + Trend2_sd),col="darkblue",alpha=0.3) +
  geom_errorbarh(aes(xmin=Trend1_mean - Trend1_sd,xmax=Trend1_mean + Trend1_sd),col="darkblue",alpha=0.3) +
  geom_text_repel(size=5,col="dark blue") +
  theme_bw() +
  xlab("Loading on trend 1") +
  ylab("Loading on trend 2")

print(g1)
```

\break  

```{r fig4, echo=FALSE, fig.pos="placeHere", fig.cap="Estimated landings for 2 species included in our analysis, with contrasting trends (lingcod, Pacific whiting). Posterior means and 95% credible intervals (ribbons) for three candidate models are shown: b-spline trend models with 6 and 18 knots, respectively, and a random walk model representing the conventional DFA model. \\label{fig:fig4}"}

df = readRDS("predicted_lingcod_whiting.rds")

# bring in raw observations
d = read.csv("data/port_landings_table2.csv", stringsAsFactors = FALSE)
obs = data.frame(year = rep(1981:2019,2),
  y = c(d[["Lingcod"]],d[["P..Whiting"]]),
  "Species"=c(rep("Lingcod",39), rep("Pacific whiting",39)))
obs = dplyr::group_by(obs, Species) %>%
  dplyr::mutate(y = (y-mean(y))/sd(y),
    Model="Random walk")

g1 = ggplot(df, aes(year, pred, group=Model, col=Model,fill=Model)) +
  geom_ribbon(aes(ymin=lower,ymax=upper),alpha=0.3,col=NA) +
  geom_line() +
  theme_bw() +
  xlab("") +
  ylab("Standardized landings (mt)") +
  scale_fill_viridis(end=0.8, discrete = TRUE) +
  scale_color_viridis(end=0.8, discrete = TRUE) +
  facet_wrap(~ Species) +
  theme(strip.background =element_rect(fill="white")) +
  geom_point(data=obs, aes(year, y),size=2, col="grey30",alpha=0.5)

print(g1)
```

\break
  
  
# References
